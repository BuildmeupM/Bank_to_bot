import streamlit as st

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ page config ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Streamlit ‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î (‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Streamlit ‡πÉ‡∏î‡πÜ)
st.set_page_config(
    page_title="Bank PDF to Excel Converter",
    page_icon="üè¶",
    layout="wide"
)

import pandas as pd
import pdfplumber
from datetime import datetime
import io
import re
from typing import Dict, List, Tuple, Optional, Any
import os
import sys
import importlib.util
import importlib.machinery
import importlib
import time
import logging
import asyncio
import subprocess
from concurrent.futures import ThreadPoolExecutor

try:
    from NewPeak import NewPeakBot
except ImportError:
    NewPeakBot = None

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ logger ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö config)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import config
try:
    import config
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ Link_conpany ‡πÅ‡∏•‡∏∞ Link_receipt ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if not hasattr(config, 'Link_conpany'):
        logger.warning("‚ö†Ô∏è config module ‡πÑ‡∏°‡πà‡∏°‡∏µ Link_conpany attribute")
    else:
        logger.info(f"‚úÖ ‡∏û‡∏ö Link_conpany ‡πÉ‡∏ô config: {getattr(config, 'Link_conpany', None)}")
    if not hasattr(config, 'Link_receipt'):
        logger.warning("‚ö†Ô∏è config module ‡πÑ‡∏°‡πà‡∏°‡∏µ Link_receipt attribute")
    else:
        logger.info(f"‚úÖ ‡∏û‡∏ö Link_receipt ‡πÉ‡∏ô config: {getattr(config, 'Link_receipt', None)}")
except ImportError:
    config = None
    logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ import config ‡πÑ‡∏î‡πâ")

# ‡πÄ‡∏Å‡πá‡∏ö bot instances ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô module level ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô garbage collection
_peakengine_bots = []
_newpeak_bots = []

# ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ asyncio event loop ‡∏ö‡∏ô Windows ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö subprocess (Playwright)
if sys.platform.startswith("win"):
    try:
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    except Exception:
        pass

# Import DBDDataWarehouseBot ‡∏à‡∏≤‡∏Å bot_data.py
try:
    # ‡∏•‡∏ö cache ‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏´‡∏°‡πà
    modules_to_remove = [key for key in sys.modules.keys() if 'bot_data' in key.lower()]
    for module_name in modules_to_remove:
        try:
            del sys.modules[module_name]
        except:
            pass
    
    # ‡∏•‡∏ö __pycache__ ‡∏î‡πâ‡∏ß‡∏¢
    import shutil
    import inspect
    current_dir = os.path.dirname(os.path.abspath(__file__))
    cache_dir = os.path.join(current_dir, '__pycache__')
    if os.path.exists(cache_dir):
        try:
            shutil.rmtree(cache_dir, ignore_errors=True)
        except:
            pass
    
    # Import ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏¢‡∏Å
    bot_data_path = os.path.join(current_dir, 'bot_data.py')
    
    if os.path.exists(bot_data_path):
        # ‡πÉ‡∏ä‡πâ unique module name ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        module_name = f"bot_data_module_{int(time.time() * 1000)}"
        spec = importlib.util.spec_from_file_location(module_name, bot_data_path)
        bot_data_module = importlib.util.module_from_spec(spec)
        sys.modules[module_name] = bot_data_module
        spec.loader.exec_module(bot_data_module)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ class ‡∏°‡∏µ use_browser parameter ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        sig = inspect.signature(bot_data_module.DBDDataWarehouseBot.__init__)
        params = list(sig.parameters.keys())
        
        if 'use_browser' not in params:
            raise AttributeError(f"bot_data.py ‡πÑ‡∏°‡πà‡∏°‡∏µ use_browser parameter ‡πÉ‡∏ô __init__ (‡∏û‡∏ö parameters: {params})")
        
        DBDDataWarehouseBot = bot_data_module.DBDDataWarehouseBot
        create_dbd_summary_table = bot_data_module.create_dbd_summary_table
        
        logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î bot_data.py ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (parameters: {params})")
    else:
        # Fallback
        logger.warning(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå bot_data.py ‡∏ó‡∏µ‡πà {bot_data_path}")
        from bot_data import DBDDataWarehouseBot, create_dbd_summary_table
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        sig = inspect.signature(DBDDataWarehouseBot.__init__)
        params = list(sig.parameters.keys())
        if 'use_browser' not in params:
            raise AttributeError(f"bot_data module ‡πÑ‡∏°‡πà‡∏°‡∏µ use_browser parameter (‡∏û‡∏ö: {params})")
        
except Exception as e:
    error_msg = str(e)
    logger.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î bot_data module ‡πÑ‡∏î‡πâ: {error_msg}")
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î bot_data module ‡πÑ‡∏î‡πâ: {error_msg}")
    st.error(f"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå bot_data.py ‡∏°‡∏µ use_browser parameter ‡πÉ‡∏ô __init__")
    st.error(f"Path ‡∏ó‡∏µ‡πà‡∏•‡∏≠‡∏á‡∏´‡∏≤: {bot_data_path if 'bot_data_path' in locals() else '‡πÑ‡∏°‡πà‡∏û‡∏ö'}")
    
    # Fallback: ‡∏™‡∏£‡πâ‡∏≤‡∏á class ‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô dummy (‡πÅ‡∏ï‡πà‡∏°‡∏µ use_browser)
    class DBDDataWarehouseBot:
        def __init__(self, use_browser=False, headless=False):
            st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î bot_data.py ‡πÑ‡∏î‡πâ: {error_msg}")
            st.stop()
        
        def search_company_info(self, company_name, log_callback=None):
            return {"error": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î bot_data module ‡πÑ‡∏î‡πâ"}
        
        def format_company_info(self, company_info):
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    
    def create_dbd_summary_table(df):
        return pd.DataFrame()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏≠‡∏ó‡∏Å‡∏±‡∏ö Streamlit
def integrate_with_streamlit(df: pd.DataFrame, company_column: str = '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•',
                              use_browser: bool = False, headless: bool = False) -> pd.DataFrame:
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Streamlit ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á bot instance ‡∏û‡∏£‡πâ‡∏≠‡∏° browser mode
    bot = DBDDataWarehouseBot(use_browser=use_browser, headless=headless)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD
    df['‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD'] = ""
    df['‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD'] = ""
    address_column_map = [
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', 'address_house_no'),
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô', 'address_village'),
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà', 'address_moo'),
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏ï‡∏≥‡∏ö‡∏•', 'address_subdistrict'),
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', 'address_district'),
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'address_province'),
        ('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå', 'address_postal_code')
    ]

    for column_name, _ in address_column_map:
        if column_name not in df.columns:
            df[column_name] = ""
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á progress bar ‡πÅ‡∏•‡∏∞ status
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    stats_container = st.container()
    with stats_container:
        col1, col2, col3, col4 = st.columns(4)
        success_count = col1.metric("‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", "0")
        error_count = col2.metric("‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", "0")
        not_found_count = col3.metric("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "0")
        total_count = col4.metric("üìä ‡∏£‡∏ß‡∏°", "0")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á container ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    log_container = st.container()
    with log_container:
        st.subheader("üìã ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó")
        log_expander = st.expander("üîç ‡∏î‡∏π‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î", expanded=False)
        log_messages = []
        log_placeholder = log_expander.empty()
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
    total_companies = len(df[df[company_column].notna() & (df[company_column] != '')])
    processed_count = 0
    success_stats = 0
    error_stats = 0
    not_found_stats = 0
    
    def log_callback(message, status="info"):
        """Callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á log"""
        log_messages.append({
            "message": message,
            "status": status,
            "time": datetime.now().strftime("%H:%M:%S")
        })
        
        # ‡πÅ‡∏™‡∏î‡∏á log ‡πÉ‡∏ô expander
        log_text = ""
        for log in log_messages[-50:]:  # ‡πÅ‡∏™‡∏î‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î 50 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
            icon = {
                "info": "‚ÑπÔ∏è",
                "success": "‚úÖ",
                "warning": "‚ö†Ô∏è",
                "error": "‚ùå"
            }.get(log["status"], "üìù")
            
            log_text += f"[{log['time']}] {icon} {log['message']}\n"
        
        log_placeholder.code(log_text, language=None)
    
    for index, row in df.iterrows():
        company_name = row[company_column]
        
        if pd.isna(company_name) or not str(company_name).strip():
            continue
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï status
        processed_count += 1
        progress = processed_count / total_companies
        progress_bar.progress(progress)
        
        status_text.text(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {processed_count}/{total_companies}: {company_name}")
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó (‡∏û‡∏£‡πâ‡∏≠‡∏° log callback)
        company_info = bot.search_company_info(str(company_name), log_callback=log_callback)
        
        # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        formatted_info = bot.format_company_info(company_info)
        df.at[index, '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD'] = formatted_info
        if isinstance(company_info, dict):
            if company_info.get("company_name"):
                df.at[index, '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD'] = company_info.get("company_name")

            for column_name, key_name in address_column_map:
                if key_name in company_info:
                    df.at[index, column_name] = company_info.get(key_name, "")
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        if "error" in company_info:
            error_stats += 1
            st.warning(f"‚ö†Ô∏è {company_name}: {company_info['error']}")
        elif formatted_info == "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•":
            not_found_stats += 1
            st.info(f"üîç {company_name}: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        else:
            success_stats += 1
            st.success(f"‚úÖ {company_name}: ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï metrics
        success_count.metric("‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", str(success_stats))
        error_count.metric("‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", str(error_stats))
        not_found_count.metric("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", str(not_found_stats))
        total_count.metric("üìä ‡∏£‡∏ß‡∏°", str(processed_count))
        
        # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        time.sleep(0.5)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    st.markdown("---")
    st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", success_stats, delta=f"{success_stats/total_companies*100:.1f}%")
    with col2:
        st.metric("‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", error_stats, delta=f"{error_stats/total_companies*100:.1f}%")
    with col3:
        st.metric("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", not_found_stats, delta=f"{not_found_stats/total_companies*100:.1f}%")
    
    # ‡∏•‡πâ‡∏≤‡∏á progress bar ‡πÅ‡∏•‡∏∞ status
    progress_bar.empty()
    status_text.empty()
    
    return df

def create_dbd_summary_table(df: pd.DataFrame) -> pd.DataFrame:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD"""
    if '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD' not in df.columns:
        return pd.DataFrame()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ
    summary_data = []
    
    for index, row in df.iterrows():
        dbd_info = row.get('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD', '')
        company_name = row.get('‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•', '')
        db_company_name = row.get('‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD', '')
        
        if dbd_info and dbd_info != "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" and "‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î" not in dbd_info:
            # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            info_parts = dbd_info.split(' | ')
            
            summary_row = {
                '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó': company_name,
                '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD': db_company_name,
                '‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô': '',
                '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à': '',
                '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞': '',
                '‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô': '',
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà': '',
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà', ''),
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô', ''),
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà', ''),
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏ï‡∏≥‡∏ö‡∏•': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏ï‡∏≥‡∏ö‡∏•', ''),
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå': row.get('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà_‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå', '')
            }
            
            for part in info_parts:
                if '‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô:' in part:
                    summary_row['‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô'] = part.replace('‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô:', '').strip()
                elif '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à:' in part:
                    summary_row['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à'] = part.replace('‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à:', '').strip()
                elif '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:' in part:
                    summary_row['‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞'] = part.replace('‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:', '').strip()
                elif '‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô:' in part:
                    summary_row['‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô'] = part.replace('‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô:', '').strip()
                elif '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà:' in part:
                    summary_row['‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà'] = part.replace('‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà:', '').strip()
            
            summary_data.append(summary_row)
    
    return pd.DataFrame(summary_data)


def test_playwright_browser(url: str = "https://datawarehouse.dbd.go.th/index") -> bool:
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î Playwright Chromium ‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á CLI"""
    try:
        command = [sys.executable, "-m", "playwright", "open", url]
        subprocess.Popen(command)
        return True
    except FileNotFoundError:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á playwright CLI ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `pip install playwright` ‡πÅ‡∏•‡∏∞ `playwright install chromium`")
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î Playwright Browser ‡πÑ‡∏î‡πâ: {e}")
    return False

def open_peakengine_login() -> bool:
    """‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PeakEngine Login ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏Å username/password ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
    try:
        # Reload config module ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        global config
        if config is not None:
            try:
                import importlib
                importlib.reload(config)
                logger.info("üîÑ Reload config module ‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ reload config ‡πÑ‡∏î‡πâ: {e}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ config ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if config is None:
            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå config.py")
            return False
        
        # Debug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö attributes ‡πÉ‡∏ô config
        try:
            attrs = [attr for attr in dir(config) if not attr.startswith('_')]
            logger.info(f"üîç Attributes ‡πÉ‡∏ô config (‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô): {', '.join(attrs)}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö attributes ‡πÑ‡∏î‡πâ: {e}")
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å config
        url = getattr(config, 'PEAKENGINE_LOGIN_URL', 'https://secure.peakengine.com/Home/Login')
        username = getattr(config, 'PEAKENGINE_USERNAME', '')
        password = getattr(config, 'PEAKENGINE_PASSWORD', '')
        headless = getattr(config, 'HEADLESS_MODE', False)
        
        # Debug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏•‡∏¥‡∏á‡∏Ñ‡πå
        link_company_check = getattr(config, 'Link_conpany', None)
        link_receipt_check = getattr(config, 'Link_receipt', None)
        logger.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô - Link_conpany: {repr(link_company_check)}, Link_receipt: {repr(link_receipt_check)}")
        
        if not username or not password:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å username ‡πÅ‡∏•‡∏∞ password ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå config.py")
            # ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            command = [sys.executable, "-m", "playwright", "open", url]
            subprocess.Popen(command)
            return True
        
        # ‡πÉ‡∏ä‡πâ PeakEngineBot class ‡πÅ‡∏ó‡∏ô (‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ browser lifecycle ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)
        try:
            from peakengine_bot import PeakEngineBot
            
            def run_bot():
                """‡∏£‡∏±‡∏ô bot ‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å"""
                bot = None
                try:
                    # Reload config module ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                    try:
                        import importlib
                        import config as config_module
                        importlib.reload(config_module)
                        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï config reference
                        global config
                        config = config_module
                        logger.info("üîÑ Reload config module ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ reload config ‡πÑ‡∏î‡πâ: {e}")
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á bot instance
                    bot = PeakEngineBot(use_browser=True, headless=headless)
                    
                    # ‡πÄ‡∏Å‡πá‡∏ö bot instance ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô module-level list ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô garbage collection
                    global _peakengine_bots
                    _peakengine_bots.append(bot)
                    logger.info(f"üìù ‡πÄ‡∏Å‡πá‡∏ö bot instance ‡πÑ‡∏ß‡πâ (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(_peakengine_bots)})")
                    
                    # Debug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö attributes ‡πÉ‡∏ô config
                    try:
                        attrs = [attr for attr in dir(config) if not attr.startswith('_')]
                        logger.info(f"üîç Attributes ‡πÉ‡∏ô config: {', '.join(attrs)}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö attributes ‡πÑ‡∏î‡πâ: {e}")
                    
                    # ‡∏≠‡πà‡∏≤‡∏ô‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡∏à‡∏≤‡∏Å config
                    link_company = getattr(config, 'Link_conpany', None)
                    link_receipt = getattr(config, 'Link_receipt', None)
                    
                    # Debug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ
                    logger.info(f"üîç link_company = {repr(link_company)}")
                    logger.info(f"üîç link_receipt = {repr(link_receipt)}")
                    
                    if link_company:
                        logger.info(f"üìñ ‡∏≠‡πà‡∏≤‡∏ô Link_conpany ‡∏à‡∏≤‡∏Å config: {link_company}")
                    else:
                        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Link_conpany ‡πÉ‡∏ô config.py")
                        # ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                        try:
                            if hasattr(config, 'Link_conpany'):
                                link_company = config.Link_conpany
                                logger.info(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô Link_conpany ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÑ‡∏î‡πâ: {link_company}")
                            else:
                                logger.warning("‚ö†Ô∏è config ‡πÑ‡∏°‡πà‡∏°‡∏µ attribute Link_conpany")
                        except Exception as e:
                            logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô Link_conpany: {e}")
                    
                    if link_receipt:
                        logger.info(f"üìñ ‡∏≠‡πà‡∏≤‡∏ô Link_receipt ‡∏à‡∏≤‡∏Å config: {link_receipt}")
                    else:
                        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Link_receipt ‡πÉ‡∏ô config.py")
                        # ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                        try:
                            if hasattr(config, 'Link_receipt'):
                                link_receipt = config.Link_receipt
                                logger.info(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô Link_receipt ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÑ‡∏î‡πâ: {link_receipt}")
                            else:
                                logger.warning("‚ö†Ô∏è config ‡πÑ‡∏°‡πà‡∏°‡∏µ attribute Link_receipt")
                        except Exception as e:
                            logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô Link_receipt: {e}")
                    
                    # ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Login
                    def log_callback(message, status="info"):
                        logger.info(f"[{status.upper()}] {message}")
                    
                    success = bot.open_login_page_and_fill(username, password, link_company=link_company, link_receipt=link_receipt, log_callback=log_callback)
                    
                    if success:
                        logger.info("‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡πÅ‡∏•‡∏∞ navigate ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                        logger.info("üëÄ Browser ‡∏à‡∏∞‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà - ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡πÅ‡∏•‡∏∞ navigate ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")
                    else:
                        logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡∏´‡∏£‡∏∑‡∏≠ navigate ‡πÑ‡∏î‡πâ - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö log")
                    
                    # ‡πÑ‡∏°‡πà‡∏õ‡∏¥‡∏î browser ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
                    # bot.close()  # ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å close() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ browser ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà
                    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: bot instance ‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô _peakengine_bots ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô garbage collection
                    
                except Exception as e:
                    logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                    logger.error(f"Error details: {e}", exc_info=True)
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î error ‡πÅ‡∏•‡∏∞ bot ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏¥‡∏î browser
                    # ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ browser ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
            
            # ‡∏£‡∏±‡∏ô‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å
            executor = ThreadPoolExecutor(max_workers=1)
            executor.submit(run_bot)
            
            return True
            
        except ImportError:
            logger.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö peakengine_bot.py - ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏õ‡∏¥‡∏î browser ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡πÅ‡∏ó‡∏ô")
            # Fallback: ‡πÄ‡∏õ‡∏¥‡∏î browser ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
            command = [sys.executable, "-m", "playwright", "open", url]
            subprocess.Popen(command)
            return True
        
    except FileNotFoundError:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á playwright CLI ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `pip install playwright` ‡πÅ‡∏•‡∏∞ `playwright install chromium`")
    except ImportError:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö playwright library ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `pip install playwright`")
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PeakEngine ‡πÑ‡∏î‡πâ: {e}")
        logger.error(f"Error details: {e}", exc_info=True)
    return False


def open_newpeak_login() -> bool:
    """‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PEAK Account (‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà) ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ Login ‡∏î‡πâ‡∏ß‡∏¢ NewPeakBot"""
    if NewPeakBot is None:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏•‡∏≤‡∏™ NewPeakBot (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå NewPeak.py ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)")
        logger.error("NewPeakBot ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡∏î‡∏π‡∏• NewPeak")
        return False

    if config is None:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå config.py ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö NewPeak")
        return False

    username = getattr(config, "NEWPEAK_USERNAME", "")
    if not username:
        username = getattr(config, "PEAKENGINE_USERNAME", "")
    password = getattr(config, "NEWPEAK_PASSWORD", "")
    if not password:
        password = getattr(config, "PEAKENGINE_PASSWORD", "")
    headless = getattr(config, "HEADLESS_MODE", False)

    if not username or not password:
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î NEWPEAK_USERNAME / NEWPEAK_PASSWORD (‡∏´‡∏£‡∏∑‡∏≠ PEAKENGINE_USERNAME / PEAKENGINE_PASSWORD) ‡πÉ‡∏ô config.py")
        return False

    def run_bot():
        bot = None
        try:
            bot = NewPeakBot(use_browser=True, headless=headless)
            _newpeak_bots.append(bot)
            logger.info(f"üÜï ‡πÄ‡∏Å‡πá‡∏ö NewPeakBot instance (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(_newpeak_bots)} ‡∏ï‡∏±‡∏ß)")

            def log_callback(message: str, status: str = "info"):
                log_func = {
                    "info": logger.info,
                    "success": logger.info,
                    "warning": logger.warning,
                    "error": logger.error,
                }.get(status, logger.info)
                log_func(f"[NewPeakBot] {message}")

            login_success = bot.login(
                username,
                password,
                navigate_after_login=True,
                log_callback=log_callback,
            )

            if login_success:
                logger.info("‚úÖ NewPeakBot Login ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Browser ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ")
            else:
                logger.warning("‚ö†Ô∏è NewPeakBot Login ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö log ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô config.py")
        except Exception as exc:
            logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô NewPeakBot: {exc}", exc_info=True)
            if bot and bot._executor:  # type: ignore[attr-defined]
                try:
                    bot.close()
                except Exception:
                    pass

    executor = ThreadPoolExecutor(max_workers=1)
    executor.submit(run_bot)
    return True


def wait_for_newpeak_login(bot, timeout: float = 60.0, poll_interval: float = 0.5, log_callback=None) -> bool:
    """‡∏£‡∏≠‡πÉ‡∏´‡πâ NewPeakBot login ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"""
    start = time.time()
    while time.time() - start < timeout:
        if getattr(bot, "is_logged_in", False):
            return True
        time.sleep(poll_interval)
    if log_callback:
        try:
            log_callback("‚ö†Ô∏è ‡∏£‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö New Peak ‡πÄ‡∏Å‡∏¥‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î", "warning")
        except Exception:
            pass
    return getattr(bot, "is_logged_in", False)


def wait_for_newpeak_instance(timeout: float = 30.0, poll_interval: float = 0.5):
    """‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot (‡∏à‡∏≤‡∏Å thread ‡∏≠‡∏∑‡πà‡∏ô)"""
    start = time.time()
    while time.time() - start < timeout:
        if _newpeak_bots:
            bot = _newpeak_bots[-1]
            if bot:
                return bot
        time.sleep(poll_interval)
    return _newpeak_bots[-1] if _newpeak_bots else None

class BankPDFReader:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á‡πÜ"""
    
    def __init__(self):
        self.bank_configs = self.load_bank_configs()
    
    def load_bank_configs(self) -> Dict:
        """‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£"""
        return {
            "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢": {
                "patterns": {
                    "date": r"(\d{2}/\d{2}/\d{4})",
                    "amount": r"([\d,]+\.\d{2})",
                    "description": r"([A-Za-z0-9\s\-\.]+)",
                    "balance": r"([\d,]+\.\d{2})"
                },
                "columns": ["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
            },
            "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û": {
                "patterns": {
                    "date": r"(\d{2}/\d{2}/\d{4})",
                    "amount": r"([\d,]+\.\d{2})",
                    "description": r"([A-Za-z0-9\s\-\.]+)",
                    "balance": r"([\d,]+\.\d{2})"
                },
                "columns": ["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
            },
            "‡∏Å‡∏£‡∏∏‡∏á‡∏®‡∏£‡∏µ": {
                "patterns": {
                    "date": r"(\d{2}/\d{2}/\d{4})",
                    "amount": r"([\d,]+\.\d{2})",
                    "description": r"([A-Za-z0-9\s\-\.]+)",
                    "balance": r"([\d,]+\.\d{2})"
                },
                "columns": ["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
            },
            "‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢": {
                "patterns": {
                    "date": r"(\d{2}/\d{2}/\d{4})",
                    "amount": r"([\d,]+\.\d{2})",
                    "description": r"([A-Za-z0-9\s\-\.]+)",
                    "balance": r"([\d,]+\.\d{2})"
                },
                "columns": ["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
            },
            "TMB": {
                "patterns": {
                    "date": r"(\d{2}/\d{2}/\d{4})",
                    "amount": r"([\d,]+\.\d{2})",
                    "description": r"([A-Za-z0-9\s\-\.]+)",
                    "balance": r"([\d,]+\.\d{2})"
                },
                "columns": ["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
            },
            "‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï": {
                "patterns": {
                    "date": r"(\d{2}/\d{2}/\d{4})",
                    "amount": r"([\d,]+\.\d{2})",
                    "description": r"([A-Za-z0-9\s\-\.]+)",
                    "balance": r"([\d,]+\.\d{2})"
                },
                "columns": ["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô", "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]
            }
        }
    
    def extract_text_from_pdf(self, pdf_file) -> str:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF"""
        try:
            with pdfplumber.open(pdf_file) as pdf:
                text = ""
                page_texts = []
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                        page_texts.append({
                            "page_number": i + 1,
                            "text": page_text,
                            "char_count": len(page_text),
                            "line_count": len(page_text.split('\n'))
                        })
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
                self.pdf_pages_info = page_texts
                return text
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF: {str(e)}")
            return ""
    
    def extract_tables_from_pdf(self, pdf_file) -> List:
        """‡∏î‡∏∂‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF"""
        try:
            tables = []
            with pdfplumber.open(pdf_file) as pdf:
                for i, page in enumerate(pdf.pages):
                    page_tables = page.extract_tables()
                    if page_tables:
                        for j, table in enumerate(page_tables):
                            tables.append({
                                "page_number": i + 1,
                                "table_number": j + 1,
                                "table_data": table,
                                "row_count": len(table),
                                "col_count": len(table[0]) if table else 0
                            })
            return tables
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {str(e)}")
            return []
    
    def analyze_kbank_statement(self, text: str) -> Dict:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢"""
        analysis = {
            "account_info": {},
            "transaction_patterns": [],
            "date_ranges": [],
            "amount_patterns": [],
            "keywords": []
        }
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ç‡∏ä‡∏µ
        account_patterns = {
            "account_number": r"‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ç‡∏ä‡∏µ[:\s]*(\d+)",
            "account_name": r"‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ç‡∏ä‡∏µ[:\s]*([^\n]+)",
            "account_type": r"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ö‡∏±‡∏ç‡∏ä‡∏µ[:\s]*([^\n]+)",
            "branch": r"‡∏™‡∏≤‡∏Ç‡∏≤[:\s]*([^\n]+)"
        }
        
        for key, pattern in account_patterns.items():
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                analysis["account_info"][key] = match.group(1).strip()
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        date_patterns = [
            r"(\d{1,2}/\d{1,2}/\d{4})",
            r"(\d{1,2}-\d{1,2}-\d{4})",
            r"(\d{4}-\d{1,2}-\d{1,2})"
        ]
        
        for pattern in date_patterns:
            dates = re.findall(pattern, text)
            analysis["date_ranges"].extend(dates)
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô
        amount_patterns = [
            r"([\d,]+\.\d{2})",
            r"([\d,]+\.\d{2})",
            r"([\d,]+)"
        ]
        
        for pattern in amount_patterns:
            amounts = re.findall(pattern, text)
            analysis["amount_patterns"].extend(amounts)
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        keywords = [
            "‡∏ñ‡∏≠‡∏ô", "‡∏ù‡∏≤‡∏Å", "‡πÇ‡∏≠‡∏ô", "‡∏ä‡∏≥‡∏£‡∏∞", "‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ", "‡∏£‡∏≤‡∏¢‡∏à‡πà‡∏≤‡∏¢",
            "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠", "‡∏¢‡∏≠‡∏î‡∏¢‡∏Å‡∏°‡∏≤", "‡∏¢‡∏≠‡∏î‡∏¢‡∏Å‡πÑ‡∏õ", "‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢",
            "‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°", "‡∏Ñ‡πà‡∏≤‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£", "ATM", "POS"
        ]
        
        for keyword in keywords:
            if keyword in text:
                analysis["keywords"].append(keyword)
        
        return analysis
    
    def parse_bank_statement(self, text: str, bank_name: str) -> pd.DataFrame:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å PDF ‡πÄ‡∏õ‡πá‡∏ô DataFrame"""
        if bank_name == "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢":
            return self.parse_kbank_statement(text)
        else:
            return self.parse_generic_statement(text, bank_name)
    
    def parse_kbank_statement(self, text: str) -> pd.DataFrame:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å PDF ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô DataFrame"""
        lines = text.split('\n')
        transactions = []
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ç‡∏ä‡∏µ
        account_info = self.extract_account_info(text)
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
        previous_balance = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÄ‡∏ß‡∏•‡∏≤ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô ‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: 01-10-25 11:17 ‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏° 51.43 22,127,753.64 ‡πÇ‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤/‡∏´‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥...
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö DD-MM-YY ‡∏´‡∏£‡∏∑‡∏≠ DD/MM/YYYY)
            date_match = re.search(r'(\d{2}[-/]\d{2}[-/]\d{2,4})', line)
            if date_match:
                date = date_match.group(1)
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡∏•‡∏≤ (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö HH:MM)
                time_match = re.search(r'(\d{2}:\d{2})', line)
                time = time_match.group(1) if time_match else ""
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö 123,456.78)
                amount_matches = re.findall(r'([\d,]+\.\d{2})', line)
                
                if len(amount_matches) >= 2:
                    amount = amount_matches[0]  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡πÅ‡∏£‡∏Å
                    balance = amount_matches[1]  # ‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠
                elif len(amount_matches) == 1:
                    amount = amount_matches[0]
                    balance = ""
                else:
                    amount = ""
                    balance = ""
                
                # ‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
                parts = line.split()
                transaction_type = ""
                description = ""
                
                # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô
                amount_pos = -1
                for i, part in enumerate(parts):
                    if re.match(r'[\d,]+\.\d{2}', part):
                        amount_pos = i
                        break
                
                # ‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà-‡πÄ‡∏ß‡∏•‡∏≤ ‡∏Å‡∏±‡∏ö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô) - ‡πÄ‡∏≠‡∏≤‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≠‡∏Å
                if amount_pos > 2:  # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÄ‡∏ß‡∏•‡∏≤ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
                    # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
                    transaction_type = " ".join(parts[2:amount_pos])
                    # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                    transaction_type = re.sub(r'\d{2}:\d{2}\s*', '', transaction_type).strip()
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡∏´‡∏•‡∏±‡∏á‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠)
                if len(amount_matches) >= 2:
                    balance_pos = -1
                    for i, part in enumerate(parts):
                        if part == balance:
                            balance_pos = i
                            break
                    
                    if balance_pos > -1 and balance_pos < len(parts) - 1:
                        description = " ".join(parts[balance_pos + 1:])
                
                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô
                amount_display = amount
                if amount and balance and previous_balance:
                    try:
                        # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                        current_balance = float(balance.replace(',', ''))
                        prev_balance = float(previous_balance.replace(',', ''))
                        amount_value = float(amount.replace(',', ''))
                        
                        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏•‡∏î‡∏•‡∏á ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏¥‡∏î‡∏•‡∏ö
                        if current_balance < prev_balance:
                            amount_display = f"({amount})"
                    except:
                        pass
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡∏•‡∏ö
                if transaction_type and any(keyword in transaction_type.lower() for keyword in ['‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°', 'fee', 'charge', 'commission']):
                    if amount and not amount_display.startswith('('):
                        amount_display = f"({amount})"
                
                transactions.append({
                    "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": date,
                    "‡πÄ‡∏ß‡∏•‡∏≤": time,
                    "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£": transaction_type,
                    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô": amount_display,
                    "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠": balance,
                    "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢": description
                })
                
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
                if balance:
                    previous_balance = balance
        
        return pd.DataFrame(transactions)
    
    def extract_account_info(self, text: str) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        account_info = {}
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ç‡∏ä‡∏µ
        account_match = re.search(r'‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡πÄ‡∏á‡∏¥‡∏ô‡∏ù‡∏≤‡∏Å\s*(\d+-\d+-\d+-\d+)', text)
        if account_match:
            account_info['account_number'] = account_match.group(1)
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ç‡∏ä‡∏µ
        name_match = re.search(r'‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ç‡∏ä‡∏µ\s*([^\n]+)', text)
        if name_match:
            account_info['account_name'] = name_match.group(1).strip()
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤
        branch_match = re.search(r'‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏ö‡∏±‡∏ç‡∏ä‡∏µ\s*([^\n]+)', text)
        if branch_match:
            account_info['branch'] = branch_match.group(1).strip()
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        period_match = re.search(r'‡∏£‡∏≠‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*(\d{2}/\d{2}/\d{4})\s*-\s*(\d{2}/\d{2}/\d{4})', text)
        if period_match:
            account_info['period_start'] = period_match.group(1)
            account_info['period_end'] = period_match.group(2)
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≠‡∏î‡∏¢‡∏Å‡πÑ‡∏õ
        balance_match = re.search(r'‡∏¢‡∏≠‡∏î‡∏¢‡∏Å‡πÑ‡∏õ\s*([\d,]+\.\d{2})', text)
        if balance_match:
            account_info['opening_balance'] = balance_match.group(1)
        
        return account_info
    
    def classify_transfer_type(self, description: str) -> str:
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°"""
        if not description:
            return "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"
        
        description_lower = description.lower()
        
        # ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó (‡∏ö‡∏à‡∏Å.)
        company_keywords = ['‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó', '‡∏ö‡∏à‡∏Å', 'company', 'co.', 'ltd', 'limited']
        if any(keyword in description_lower for keyword in company_keywords):
            return "‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó (‡∏ö‡∏à‡∏Å.)"
        
        # ‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô (‡∏´‡∏à‡∏Å.)
        partnership_keywords = ['‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô', '‡∏´‡∏à‡∏Å', 'partnership']
        if any(keyword in description_lower for keyword in partnership_keywords):
            return "‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô (‡∏´‡∏à‡∏Å.)"
        
        # ‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
        person_keywords = ['‡∏ô‡∏≤‡∏¢', '‡∏ô‡∏≤‡∏á', '‡∏ô.‡∏™.', 'miss', 'mr', 'mrs', 'ms', '‡∏ô‡∏™.']
        if any(keyword in description_lower for keyword in person_keywords):
            return "‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• (‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•)
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
        if re.search(r'[‡∏Å-‡πô]+\s+[‡∏Å-‡πô]+', description) and len(description.split()) <= 3:
            return "‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"
        
        return "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"
    
    def extract_entity_name(self, description: str) -> str:
        """‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢"""
        if not description:
            return ""
        
        description_lower = description.lower()
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢
        patterns = [
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ...
            r'‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏Å‡∏£|\s+‡∏à‡∏≥‡∏Å‡∏±‡∏î|\s+‡∏°‡∏´‡∏≤‡∏ä‡∏ô|\s+‡∏Ø‡∏•‡∏Ø|\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏ö‡∏à‡∏Å. ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ...
            r'‡∏ö‡∏à‡∏Å\.\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏Å‡∏£|\s+‡∏à‡∏≥‡∏Å‡∏±‡∏î|\s+‡∏°‡∏´‡∏≤‡∏ä‡∏ô|\s+‡∏Ø‡∏•‡∏Ø|\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡πâ‡∏≤‡∏á ...
            r'‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏Å‡∏£|\s+‡∏à‡∏≥‡∏Å‡∏±‡∏î|\s+‡∏°‡∏´‡∏≤‡∏ä‡∏ô|\s+‡∏Ø‡∏•‡∏Ø|\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏ô‡∏≤‡∏¢ ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'‡∏ô‡∏≤‡∏¢\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏ô‡∏≤‡∏á ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'‡∏ô‡∏≤‡∏á\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏ô.‡∏™. ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'‡∏ô\.‡∏™\.\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... ‡∏ô‡∏™. ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'‡∏ô‡∏™\.\s+([‡∏Å-‡πôA-Za-z0-9\s\.\-\+]+?)(?:\s+‡∏à‡∏≤‡∏Å|\s+‡∏ñ‡∏∂‡∏á|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... Mr. ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'mr\.?\s+([A-Za-z0-9\s\.\-\+]+?)(?:\s+from|\s+to|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... Miss ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'miss\s+([A-Za-z0-9\s\.\-\+]+?)(?:\s+from|\s+to|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... Mrs. ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'mrs\.?\s+([A-Za-z0-9\s\.\-\+]+?)(?:\s+from|\s+to|\s+$|$)',
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ... Ms. ‡∏ä‡∏∑‡πà‡∏≠ ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏• ...
            r'ms\.?\s+([A-Za-z0-9\s\.\-\+]+?)(?:\s+from|\s+to|\s+$|$)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, description, re.IGNORECASE)
            if match:
                entity_name = match.group(1).strip()
                
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠
                entity_name = re.sub(r'\s+', ' ', entity_name)  # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
                
                # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                entity_name = re.sub(r'\b‡∏ö‡∏à‡∏Å\.?\b', '', entity_name, flags=re.IGNORECASE)  # ‡∏•‡∏ö "‡∏ö‡∏à‡∏Å."
                entity_name = re.sub(r'\b‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó\b', '', entity_name, flags=re.IGNORECASE)  # ‡∏•‡∏ö "‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó"
                entity_name = re.sub(r'\b‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô\b', '', entity_name, flags=re.IGNORECASE)  # ‡∏•‡∏ö "‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô"
                entity_name = re.sub(r'\b‡∏à‡∏≥‡∏Å‡∏±‡∏î\b', '', entity_name, flags=re.IGNORECASE)  # ‡∏•‡∏ö "‡∏à‡∏≥‡∏Å‡∏±‡∏î"
                entity_name = re.sub(r'\b‡∏°‡∏´‡∏≤‡∏ä‡∏ô\b', '', entity_name, flags=re.IGNORECASE)  # ‡∏•‡∏ö "‡∏°‡∏´‡∏≤‡∏ä‡∏ô"
                
                # ‡∏•‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                entity_name = re.sub(r'\+\+', '', entity_name)  # ‡∏•‡∏ö "++"
                entity_name = re.sub(r'\+', '', entity_name)  # ‡∏•‡∏ö "+"
                entity_name = re.sub(r'‡∏Ø‡∏•‡∏Ø', '', entity_name)  # ‡∏•‡∏ö "‡∏Ø‡∏•‡∏Ø"
                
                # ‡∏•‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©
                entity_name = re.sub(r'^[0-9\-\+\.\s]+', '', entity_name)
                
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                entity_name = re.sub(r'\s+', ' ', entity_name)  # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≥
                entity_name = entity_name.strip()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)
                if len(entity_name) <= 100 and len(entity_name) > 0:
                    return entity_name
        
        return ""
    
    def format_date_column(self, df: pd.DataFrame) -> pd.DataFrame:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/MM/yyyy"""
        if df.empty or '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' not in df.columns:
            return df
        
        df_formatted = df.copy()
        
        def convert_date_format(date_str):
            if not date_str or pd.isna(date_str):
                return date_str
            
            try:
                # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢
                date_patterns = [
                    # DD-MM-YY (‡πÄ‡∏ä‡πà‡∏ô 01-10-25)
                    r'(\d{2})-(\d{2})-(\d{2})',
                    # DD/MM/YYYY (‡πÄ‡∏ä‡πà‡∏ô 01/10/2025)
                    r'(\d{2})/(\d{2})/(\d{4})',
                    # DD-MM-YYYY (‡πÄ‡∏ä‡πà‡∏ô 01-10-2025)
                    r'(\d{2})-(\d{2})-(\d{4})',
                    # YYYY-MM-DD (‡πÄ‡∏ä‡πà‡∏ô 2025-10-01)
                    r'(\d{4})-(\d{2})-(\d{2})',
                ]
                
                for pattern in date_patterns:
                    match = re.match(pattern, str(date_str).strip())
                    if match:
                        if len(match.groups()) == 3:
                            day, month, year = match.groups()
                            
                            # ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏µ 2 ‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô 4 ‡∏´‡∏•‡∏±‡∏Å
                            if len(year) == 2:
                                year_int = int(year)
                                if year_int >= 0 and year_int <= 30:  # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ 00-30 ‡πÄ‡∏õ‡πá‡∏ô 2000-2030
                                    year = f"20{year}"
                                else:  # 31-99 ‡πÄ‡∏õ‡πá‡∏ô 1931-1999
                                    year = f"19{year}"
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/MM/yyyy
                            return f"{day.zfill(2)}/{month.zfill(2)}/{year}"
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏î‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
                return date_str
                
            except Exception:
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
                return date_str
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        df_formatted['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'] = df_formatted['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].apply(convert_date_format)
        
        return df_formatted
    
    def create_transfer_summary(self, df: pd.DataFrame) -> pd.DataFrame:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô"""
        if df.empty or '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' not in df.columns:
            return pd.DataFrame()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô (‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢)
        df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] = df['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(self.classify_transfer_type)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
        df['‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•'] = df['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(self.extract_entity_name)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ
        summary_data = []
        
        for transfer_type in df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'].unique():
            type_data = df[df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] == transfer_type]
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
            count = len(type_data)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°
            total_amount = 0
            positive_amount = 0
            negative_amount = 0
            
            for amount in type_data['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô']:
                if amount and amount != "":
                    try:
                        # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                        clean_amount = amount.replace(',', '').replace('(', '').replace(')', '')
                        amount_value = float(clean_amount)
                        
                        if '(' in amount and ')' in amount:
                            # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏•‡∏ö
                            total_amount -= amount_value
                            negative_amount += amount_value
                        else:
                            # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏ß‡∏Å
                            total_amount += amount_value
                            positive_amount += amount_value
                    except:
                        pass
            
            summary_data.append({
                '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô': transfer_type,
                '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£': count,
                '‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°': f"{total_amount:,.2f}",
                '‡∏¢‡∏≠‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°': f"{positive_amount:,.2f}",
                '‡∏¢‡∏≠‡∏î‡∏•‡∏î': f"{negative_amount:,.2f}",
                '‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞': f"{(count/len(df)*100):.1f}%"
            })
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢)
        summary_df = pd.DataFrame(summary_data)
        summary_df = summary_df.sort_values('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£', ascending=False)
        
        return summary_df
    
    def parse_generic_statement(self, text: str, bank_name: str) -> pd.DataFrame:
        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å PDF ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏õ‡πá‡∏ô DataFrame"""
        config = self.bank_configs.get(bank_name, self.bank_configs["‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢"])
        
        lines = text.split('\n')
        transactions = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
            date_match = re.search(config["patterns"]["date"], line)
            if date_match:
                date = date_match.group(1)
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô
                amount_match = re.search(config["patterns"]["amount"], line)
                amount = amount_match.group(1) if amount_match else ""
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
                description_match = re.search(config["patterns"]["description"], line)
                description = description_match.group(1) if description_match else ""
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠
                balance_match = re.search(config["patterns"]["balance"], line)
                balance = balance_match.group(1) if balance_match else ""
                
                transactions.append({
                    "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": date,
                    "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£": description,
                    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô": amount,
                    "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠": balance
                })
        
        return pd.DataFrame(transactions)
    
    def detect_bank(self, text: str) -> str:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÑ‡∏´‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        bank_keywords = {
            "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢": ["‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢", "Kasikorn", "KBank"],
            "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û": ["‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û", "Bangkok Bank", "BBL"],
            "‡∏Å‡∏£‡∏∏‡∏á‡∏®‡∏£‡∏µ": ["‡∏Å‡∏£‡∏∏‡∏á‡∏®‡∏£‡∏µ", "Krungsri", "Bank of Ayudhya"],
            "‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢": ["‡∏Å‡∏£‡∏∏‡∏á‡πÑ‡∏ó‡∏¢", "Krung Thai", "KTB"],
            "TMB": ["TMB", "‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢"],
            "‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï": ["‡∏ò‡∏ô‡∏ä‡∏≤‡∏ï", "Thanachart", "TBank"]
        }
        
        text_lower = text.lower()
        for bank, keywords in bank_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    return bank
        
        return "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢"  # default

def process_pdf_file(uploaded_file, reader, selected_bank):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå PDF ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå PDF..."):
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å PDF
        text = reader.extract_text_from_pdf(uploaded_file)
        
        if text:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            detected_bank = reader.detect_bank(text)
            st.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£: {detected_bank}")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            st.header("üîç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏à‡∏≤‡∏Å PDF")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
            if hasattr(reader, 'pdf_pages_info'):
                st.subheader("üìÑ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤")
                for page_info in reader.pdf_pages_info:
                    with st.expander(f"‡∏´‡∏ô‡πâ‡∏≤ {page_info['page_number']} ({page_info['char_count']} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£, {page_info['line_count']} ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)"):
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                        lines = page_info['text'].split('\n')
                        if lines:
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
                            raw_data = []
                            for i, line in enumerate(lines):
                                if line.strip():
                                    raw_data.append({
                                        "‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î": i + 1,
                                        "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤": line.strip()
                                    })
                            
                            if raw_data:
                                df_raw = pd.DataFrame(raw_data)
                                st.dataframe(df_raw, use_container_width=True, height=300)
                            else:
                                st.text(page_info['text'])
            
            # ‡∏î‡∏∂‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏≤‡∏Å PDF
            tables = reader.extract_tables_from_pdf(uploaded_file)
            if tables:
                st.subheader("üìä ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô PDF")
                for table_info in tables:
                    with st.expander(f"‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà {table_info['table_number']} ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ {table_info['page_number']} ({table_info['row_count']} ‡πÅ‡∏ñ‡∏ß, {table_info['col_count']} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)"):
                        if table_info['table_data']:
                            df_table = pd.DataFrame(table_info['table_data'])
                            st.dataframe(df_table, use_container_width=True)
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢
            if detected_bank == "‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢":
                st.subheader("üè¶ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Å‡∏™‡∏¥‡∏Å‡∏£‡πÑ‡∏ó‡∏¢")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ç‡∏ä‡∏µ
                account_info = reader.extract_account_info(text)
                if account_info:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏ç‡∏ä‡∏µ:**")
                        for key, value in account_info.items():
                            if key == 'account_number':
                                st.write(f"- ‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ç‡∏ä‡∏µ: {value}")
                            elif key == 'account_name':
                                st.write(f"- ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ç‡∏ä‡∏µ: {value}")
                            elif key == 'branch':
                                st.write(f"- ‡∏™‡∏≤‡∏Ç‡∏≤: {value}")
                            elif key == 'period_start':
                                st.write(f"- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {value}")
                            elif key == 'period_end':
                                st.write(f"- ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î: {value}")
                            elif key == 'opening_balance':
                                st.write(f"- ‡∏¢‡∏≠‡∏î‡∏¢‡∏Å‡πÑ‡∏õ: {value}")
                    
                    with col2:
                        st.write("**‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:**")
                        st.write(f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(text.split('\n'))}")
                        st.write(f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£: {len(text)}")
                        
                        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°
                        transaction_lines = []
                        for line in text.split('\n'):
                            if re.search(r'\d{2}[-/]\d{2}[-/]\d{2,4}', line):
                                transaction_lines.append(line)
                        
                        st.write(f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏ö: {len(transaction_lines)}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                analysis = reader.analyze_kbank_statement(text)
                
                if analysis["date_ranges"]:
                    st.write(f"**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏û‡∏ö:** {len(analysis['date_ranges'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    unique_dates = list(set(analysis["date_ranges"]))[:10]
                    st.write(f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: {', '.join(unique_dates)}")
                
                if analysis["amount_patterns"]:
                    st.write(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö:** {len(analysis['amount_patterns'])} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    unique_amounts = list(set(analysis["amount_patterns"]))[:10]
                    st.write(f"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: {', '.join(unique_amounts)}")
                
                if analysis["keywords"]:
                    st.write(f"**‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏û‡∏ö:** {', '.join(analysis['keywords'])}")
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            df = reader.parse_bank_statement(text, detected_bank)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô dd/MM/yyyy
            df = reader.format_date_column(df)

            def parse_amount_value(amount_str):
                if amount_str is None or (isinstance(amount_str, float) and pd.isna(amount_str)):
                    return None
                text_amount = str(amount_str).strip()
                if not text_amount:
                    return None
                negative = False
                if text_amount.startswith('(') and text_amount.endswith(')'):
                    negative = True
                    text_amount = text_amount[1:-1]
                text_amount = text_amount.replace(',', '').replace('+', '').strip()
                try:
                    value = float(text_amount)
                    return -value if negative else value
                except ValueError:
                    return None

            if not df.empty and '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô' in df.columns:
                df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] = df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'].apply(parse_amount_value)
            else:
                df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] = pd.Series(dtype=float)

            if not df.empty and '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' in df.columns:
                df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] = df['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(reader.classify_transfer_type)
                st.subheader("üè∑Ô∏è ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö")
                category_counts = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'].value_counts()
                category_summary = pd.DataFrame({
                    '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô': category_counts.index,
                    '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£': category_counts.values
                })
                st.dataframe(category_summary, use_container_width=True, hide_index=True)

            if not df.empty and '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric' in df.columns:
                income_df = df[df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] > 0]
                expense_df = df[df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] < 0]
                st.subheader("üí∞ ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤/‡πÄ‡∏á‡∏¥‡∏ô‡∏≠‡∏≠‡∏Å")
                col_in, col_out, col_net = st.columns(3)
                with col_in:
                    st.metric("‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ (Income)", f"{income_df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'].sum():,.2f}", help="‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ß‡∏Å")
                    st.caption(f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤: {len(income_df)}")
                with col_out:
                    st.metric("‡πÄ‡∏á‡∏¥‡∏ô‡∏≠‡∏≠‡∏Å (Expense)", f"{expense_df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'].sum():,.2f}", help="‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏ö")
                    st.caption(f"‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏≠‡∏≠‡∏Å: {len(expense_df)}")
                with col_net:
                    net_amount = df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'].sum()
                    st.metric("‡∏¢‡∏≠‡∏î‡∏™‡∏∏‡∏ó‡∏ò‡∏¥", f"{net_amount:,.2f}", help="‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ - ‡πÄ‡∏á‡∏¥‡∏ô‡∏≠‡∏≠‡∏Å")
            
            if not df.empty:
                st.success("‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in df.columns:
                    st.info("üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/MM/yyyy ‡πÅ‡∏•‡πâ‡∏ß")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
                st.header("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏µ (‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ß‡∏•‡∏≤)
                display_columns = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô', '‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠']
                if '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' in df.columns:
                    display_columns.append('‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢')
                if '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô' in df.columns:
                    display_columns.append('‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô')
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
                if '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' in df.columns:
                    df_display = df.copy()
                    df_display['‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•'] = df_display['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(reader.extract_entity_name)
                    if '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•' in df_display.columns:
                        display_columns.append('‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•')
                else:
                    df_display = df
                
                available_columns = [col for col in display_columns if col in df_display.columns]
                
                st.dataframe(
                    df_display[available_columns], 
                    use_container_width=True, 
                    height=400,
                    column_config={
                        "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": st.column_config.TextColumn(
                            "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà",
                            help="‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏° (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/MM/yyyy)"
                        ),
                        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô": st.column_config.TextColumn(
                            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô",
                            help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏° (‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏•‡∏î‡∏•‡∏á)"
                        ),
                        "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•": st.column_config.TextColumn(
                            "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
                            help="‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏° (‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢)"
                        )
                    }
                )
                
                # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", len(df))
                with col2:
                    st.metric("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô", df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].min() if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in df.columns else "N/A")
                with col3:
                    st.metric("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î", df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].max() if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in df.columns else "N/A")
                with col4:
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î
                    if '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric' in df.columns and not df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'].isna().all():
                        total_amount = df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'].sum()
                        positive_count = int((df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] > 0).sum())
                        negative_count = int((df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] < 0).sum())
                        
                        st.metric("‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°", f"{total_amount:,.2f}")
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                        st.write(f"üìà ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°: {positive_count}")
                        st.write(f"üìâ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏î: {negative_count}")
                    else:
                        st.metric("‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°", "N/A")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                if '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£' in df.columns:
                    st.subheader("üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
                    transaction_summary = df['‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£'].value_counts()
                    st.bar_chart(transaction_summary)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô
                if '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' in df.columns:
                    st.subheader("üè¢ ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô")
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ
                    transfer_summary = reader.create_transfer_summary(df.copy())
                    
                    if not transfer_summary.empty:
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ
                        st.dataframe(
                            transfer_summary,
                            use_container_width=True,
                            column_config={
                                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô": st.column_config.TextColumn(
                                    "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô",
                                    help="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô‡πÄ‡∏á‡∏¥‡∏ô"
                                ),
                                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£": st.column_config.NumberColumn(
                                    "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£",
                                    help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°"
                                ),
                                "‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°": st.column_config.TextColumn(
                                    "‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°",
                                    help="‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
                                ),
                                "‡∏¢‡∏≠‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°": st.column_config.TextColumn(
                                    "‡∏¢‡∏≠‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°",
                                    help="‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤"
                                ),
                                "‡∏¢‡∏≠‡∏î‡∏•‡∏î": st.column_config.TextColumn(
                                    "‡∏¢‡∏≠‡∏î‡∏•‡∏î",
                                    help="‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏•‡∏î‡∏•‡∏á"
                                ),
                                "‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞": st.column_config.TextColumn(
                                    "‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞",
                                    help="‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"
                                )
                            }
                        )
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.write("**üìä ‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£:**")
                            chart_data = transfer_summary.set_index('‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô')['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£']
                            st.bar_chart(chart_data)
                        
                        with col2:
                            st.write("**üí∞ ‡∏Å‡∏£‡∏≤‡∏ü‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°:**")
                            # ‡πÅ‡∏õ‡∏•‡∏á‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü
                            chart_amounts = []
                            for amount_str in transfer_summary['‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°']:
                                try:
                                    amount_value = float(amount_str.replace(',', ''))
                                    chart_amounts.append(amount_value)
                                except:
                                    chart_amounts.append(0)
                            
                            chart_df = pd.DataFrame({
                                '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô': transfer_summary['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'],
                                '‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°': chart_amounts
                            }).set_index('‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô')
                            
                            st.bar_chart(chart_df['‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°'])
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                        st.subheader("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
                        
                        for transfer_type in transfer_summary['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô']:
                            type_count = transfer_summary[transfer_summary['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] == transfer_type]['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£'].iloc[0]
                            type_total = transfer_summary[transfer_summary['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] == transfer_type]['‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°'].iloc[0]
                            
                            with st.expander(f"üîç {transfer_type} ({type_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°: {type_total})"):
                                type_data = df[df['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(reader.classify_transfer_type) == transfer_type]
                                
                                if not type_data.empty:
                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏¢‡πà‡∏≠‡∏¢
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", type_count)
                                    with col2:
                                        st.metric("‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°", type_total)
                                    with col3:
                                        st.metric("‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞", transfer_summary[transfer_summary['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] == transfer_type]['‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞'].iloc[0])
                                    
                                    st.markdown("---")
                                    
                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°
                                    st.write(f"**‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ({type_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£):**")
                                    
                                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                                        if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in type_data.columns:
                                            unique_dates = sorted(type_data['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].unique())
                                            selected_dates = st.multiselect(
                                                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:",
                                                unique_dates,
                                                default=unique_dates,
                                                key=f"date_filter_{transfer_type}"
                                            )
                                            if selected_dates:
                                                type_data = type_data[type_data['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].isin(selected_dates)]
                                    
                                    with col2:
                                        # ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô
                                        amount_filter = st.selectbox(
                                            "‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô:",
                                            ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°", "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏î"],
                                            key=f"amount_filter_{transfer_type}"
                                        )
                                        if '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric' in type_data.columns:
                                            if amount_filter == "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°":
                                                type_data = type_data[type_data['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] > 0]
                                            elif amount_filter == "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏î":
                                                type_data = type_data[type_data['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] < 0]
                                        else:
                                            if amount_filter == "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°":
                                                type_data = type_data[type_data['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'].str.contains(r'^\d', na=False)]
                                            elif amount_filter == "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏î":
                                                type_data = type_data[type_data['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'].str.contains(r'^\(', na=False)]
                                    
                                    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á
                                    display_columns = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô', '‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠']
                                    if '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' in type_data.columns:
                                        display_columns.append('‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢')
                                    if '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•' in type_data.columns:
                                        display_columns.append('‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•')
                                    
                                    available_columns = [col for col in display_columns if col in type_data.columns]
                                    
                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
                                    filtered_count = len(type_data)
                                    if filtered_count != type_count:
                                        st.info(f"üìä ‡πÅ‡∏™‡∏î‡∏á {filtered_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {type_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                                    
                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
                                    st.dataframe(
                                        type_data[available_columns], 
                                        use_container_width=True,
                                        height=400,
                                        column_config={
                                            "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": st.column_config.TextColumn(
                                                "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà",
                                                help="‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏° (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö dd/MM/yyyy)"
                                            ),
                                            "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£": st.column_config.TextColumn(
                                                "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£",
                                                help="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°"
                                            ),
                                            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô": st.column_config.TextColumn(
                                                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô",
                                                help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô (‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏•‡∏î‡∏•‡∏á)"
                                            ),
                                            "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠": st.column_config.TextColumn(
                                                "‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠",
                                                help="‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°"
                                            ),
                                            "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢": st.column_config.TextColumn(
                                                "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢",
                                                help="‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°"
                                            ),
                                            "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•": st.column_config.TextColumn(
                                                "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
                                                help="‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏° (‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢)"
                                            )
                                        }
                                    )
                                    
                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡πà‡∏≠‡∏¢
                                    st.markdown("---")
                                    st.write("**‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡πà‡∏≠‡∏¢:**")
                                    
                                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                                    if '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric' in type_data.columns:
                                        positive_count = int((type_data['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] > 0).sum())
                                        negative_count = int((type_data['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] < 0).sum())
                                    else:
                                        positive_count = len(type_data[type_data['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'].str.contains(r'^\d', na=False)])
                                        negative_count = len(type_data[type_data['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô'].str.contains(r'^\(', na=False)])
                                    
                                    col1, col2, col3, col4 = st.columns(4)
                                    with col1:
                                        st.write(f"üìà ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°: {positive_count}")
                                    with col2:
                                        st.write(f"üìâ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏î: {negative_count}")
                                    with col3:
                                        st.write(f"üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°: {type_data['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].min()}")
                                    with col4:
                                        st.write(f"üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î: {type_data['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].max()}")
                                        
                                else:
                                    st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                    else:
                        st.write("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î)
                if '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô' in df.columns:
                    st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á")
                    
                    # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á
                    positive_transactions = df[df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] > 0] if '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric' in df.columns else pd.DataFrame()
                    negative_transactions = df[df['‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric'] < 0] if '‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric' in df.columns else pd.DataFrame()
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**üìà ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°:**")
                        if not positive_transactions.empty:
                            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏•‡∏≤)
                            display_columns = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô', '‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠']
                            available_columns = [col for col in display_columns if col in positive_transactions.columns]
                            st.dataframe(positive_transactions[available_columns], use_container_width=True)
                        else:
                            st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°")
                    
                    with col2:
                        st.write("**üìâ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏•‡∏î:**")
                        if not negative_transactions.empty:
                            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏•‡∏≤)
                            display_columns = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô', '‡∏¢‡∏≠‡∏î‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠']
                            available_columns = [col for col in display_columns if col in negative_transactions.columns]
                            st.dataframe(negative_transactions[available_columns], use_container_width=True)
                        else:
                            st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏•‡∏î")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in df.columns:
                    st.subheader("üìÖ ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà")
                    date_summary = df['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà'].value_counts().sort_index()
                    st.line_chart(date_summary)
                
                # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel
                st.header("üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
                    output_raw = io.BytesIO()
                    with pd.ExcelWriter(output_raw, engine='openpyxl') as writer:
                        df.to_excel(writer, sheet_name='Bank_Statement', index=False)
                    
                    output_raw.seek(0)
                    
                    st.download_button(
                        label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö",
                        data=output_raw.getvalue(),
                        file_name=f"bank_statement_raw_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        help="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó",
                        key="download_raw_pdf"
                    )
                
                with col2:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏•‡πâ‡∏ß
                    if '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢' in df.columns:
                        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                        df_classified = df.copy()
                        df_classified['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] = df_classified['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(reader.classify_transfer_type)
                        df_classified['‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•'] = df_classified['‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢'].apply(reader.extract_entity_name)
                        
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ
                        transfer_summary = reader.create_transfer_summary(df.copy())
                        
                        output_classified = io.BytesIO()
                        with pd.ExcelWriter(output_classified, engine='openpyxl') as writer:
                            # Sheet 1: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏•‡πâ‡∏ß
                            df_classified.to_excel(writer, sheet_name='‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏•‡πâ‡∏ß', index=False)
                            
                            # Sheet 2: ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                            if not transfer_summary.empty:
                                transfer_summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó', index=False)
                            
                            # Sheet 3: ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô
                            for transfer_type in df_classified['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'].unique():
                                type_data = df_classified[df_classified['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô'] == transfer_type]
                                sheet_name = f"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó_{transfer_type}"[:31]  # Excel sheet name limit
                                type_data.to_excel(writer, sheet_name=sheet_name, index=False)
                        
                        output_classified.seek(0)
                        
                        st.download_button(
                            label="üìä ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏•‡πâ‡∏ß",
                            data=output_classified.getvalue(),
                            file_name=f"bank_statement_classified_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            help="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó",
                            key="download_classified_pdf"
                        )
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢")
            else:
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏°‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                st.subheader("üìù ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                lines = text.split('\n')
                raw_data = []
                for i, line in enumerate(lines):
                    if line.strip():
                        raw_data.append({
                            "‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î": i + 1,
                            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤": line.strip()
                        })
                
                if raw_data:
                    df_raw = pd.DataFrame(raw_data)
                    st.dataframe(df_raw, use_container_width=True, height=400)
                else:
                    st.text_area("‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å PDF:", text, height=400)
        else:
            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF ‡πÑ‡∏î‡πâ")

def render_statement_page(reader, selected_bank):
    """‡∏´‡∏ô‡πâ‡∏≤ Statement - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PDF ‡πÅ‡∏•‡∏∞ Excel ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£"""
    st.header("üìÑ Statement - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Statement ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£")
    st.markdown("---")
    
    # ‡πÅ‡∏ó‡πá‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î PDF ‡πÅ‡∏•‡∏∞ Excel
    tab1, tab2 = st.tabs(["üìÑ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF", "üìä ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel"])
    
    uploaded_file = None
    
    with tab1:
        st.write("**‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£**")
        
        # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF
        st.subheader("üìÅ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF")
        uploaded_file = st.file_uploader(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£",
            type=['pdf'],
            help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡∏Ç‡∏≠‡∏á‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
            key="pdf_upload_statement"
        )
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        if uploaded_file is not None:
            st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {uploaded_file.name}")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå", f"{uploaded_file.size / 1024:.1f} KB")
            with col2:
                st.metric("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå", uploaded_file.type)
            with col3:
                st.metric("‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", selected_bank)
            
            # ‡∏õ‡∏∏‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            if st.button("üîÑ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå PDF", type="primary", key="process_pdf_btn"):
                process_pdf_file(uploaded_file, reader, selected_bank)
    
    with tab2:
        st.write("**‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó**")
        
        # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel
        st.subheader("üìä ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel")
        uploaded_excel = st.file_uploader(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel",
            type=['xlsx', 'xls'],
            help="‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
            key="excel_upload_statement"
        )
        
        if uploaded_excel is not None:
            try:
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel
                df_excel = pd.read_excel(uploaded_excel)
                
                st.success("‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
                st.subheader("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
                st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß: {len(df_excel)}")
                st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {len(df_excel.columns)}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
                st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà:**")
                st.write(", ".join(df_excel.columns.tolist()))
                
                # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
                company_columns = [col for col in df_excel.columns if any(keyword in col.lower() for keyword in ['‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó', '‡∏ä‡∏∑‡πà‡∏≠', 'company', 'name'])]
                
                if company_columns:
                    selected_column = st.selectbox(
                        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:",
                        company_columns,
                        help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
                        key="company_column_statement"
                    )
                    
                    if selected_column:
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
                        st.subheader("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
                        st.dataframe(df_excel.head(10), use_container_width=True)
                        
                        # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if st.button("üîç ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD ‡∏à‡∏≤‡∏Å Excel", type="primary", key="fetch_dbd_excel_statement"):
                                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
                                st.subheader("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD DataWarehouse")
                                
                                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                                st.write(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•:** {len(df_excel[df_excel[selected_column].notna() & (df_excel[selected_column] != '')])}")
                                st.write(f"**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:** {selected_column}")
                                
                                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                                st.write("**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•:**")
                                sample_data = df_excel[df_excel[selected_column].notna() & (df_excel[selected_column] != '')][selected_column].head(5)
                                for i, company in enumerate(sample_data, 1):
                                    st.write(f"{i}. {company}")
                                
                                st.markdown("---")
                                
                                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD DataWarehouse..."):
                                    try:
                                        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD
                                        use_browser_mode = st.session_state.get('use_browser_mode', True)
                                        headless_mode = st.session_state.get('headless_mode', False)
                                        
                                        df_excel_with_dbd = integrate_with_streamlit(
                                            df_excel.copy(), 
                                            selected_column,
                                            use_browser=use_browser_mode,
                                            headless=headless_mode
                                        )
                                        
                                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                                        st.success("‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD DataWarehouse ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                                        
                                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD
                                        dbd_summary = create_dbd_summary_table(df_excel_with_dbd)
                                        
                                        if not dbd_summary.empty:
                                            st.subheader("üìã ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD")
                                            st.dataframe(dbd_summary, use_container_width=True)
                                        
                                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD
                                        output_dbd = io.BytesIO()
                                        with pd.ExcelWriter(output_dbd, engine='openpyxl') as writer:
                                            df_excel_with_dbd.to_excel(writer, sheet_name='‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD', index=False)
                                            
                                            if not dbd_summary.empty:
                                                dbd_summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD', index=False)
                                        
                                        output_dbd.seek(0)
                                        
                                        st.download_button(
                                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD",
                                            data=output_dbd.getvalue(),
                                            file_name=f"excel_with_dbd_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                            help="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Excel ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD DataWarehouse",
                                            key="download_dbd_excel_statement"
                                        )
                                        
                                    except Exception as e:
                                        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
                        
                        with col2:
                            st.info("""
                            **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:**
                            ‚Ä¢ ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
                            ‚Ä¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
                            ‚Ä¢ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å [DBD DataWarehouse](https://datawarehouse.dbd.go.th/index)
                            """)
                else:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                    st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà:**")
                    for col in df_excel.columns:
                        st.write(f"‚Ä¢ {col}")
            
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel: {str(e)}")
    
    return uploaded_file, selected_bank

def render_dbd_bot_page(reader):
    """‡∏´‡∏ô‡πâ‡∏≤ Bot ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏°‡∏û‡∏±‡∏í‡∏ô‡πå - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD"""
    st.header("ü§ñ Bot ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏°‡∏û‡∏±‡∏í‡∏ô‡πå")
    st.markdown("---")
    st.write("**‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD DataWarehouse**")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
    use_browser_mode = st.session_state.get('use_browser_mode', True)
    headless_mode = st.session_state.get('headless_mode', False)
    
    if use_browser_mode:
        if headless_mode:
            st.info("üåê ‡πÇ‡∏´‡∏°‡∏î: Chromium Browser (Headless) - Browser ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡∏ã‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠")
        else:
            st.success("üåê ‡πÇ‡∏´‡∏°‡∏î: Chromium Browser (‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠) - üëÄ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Chromium window ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà")
    else:
        st.info("üì° ‡πÇ‡∏´‡∏°‡∏î: Requests Mode - ‡πÉ‡∏ä‡πâ requests library ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤")
    
    st.markdown("---")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    mode = st.radio(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î:",
        ["üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß", "üìä ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel"],
        help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏≠‡∏ó DBD",
        key="dbd_bot_mode"
    )
    
    if mode == "üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß":
        st.subheader("üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó")
        
        # ‡∏ä‡πà‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        company_name = st.text_input(
            "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:",
            placeholder="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ó‡∏£‡∏≠‡πÄ‡∏ß‡∏•‡∏•‡πå ‡∏Å‡∏£",
            help="‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤",
            key="company_search_input"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            search_button = st.button("üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤", type="primary", use_container_width=True, key="search_company_btn")
        
        with col2:
            if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", use_container_width=True, key="clear_search_btn"):
                st.rerun()
        
        if search_button and company_name:
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ browser mode
            if use_browser_mode and not headless_mode:
                st.info("üëÄ **‡∏î‡∏π Chromium Browser ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà** - ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå!")
            
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
                log_messages = []
                log_expander = st.expander("üîç ‡∏î‡∏π‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", expanded=True)
                
                def log_callback(message, status="info"):
                    log_messages.append({
                        "message": message,
                        "status": status,
                        "time": datetime.now().strftime("%H:%M:%S")
                    })
                    
                    # ‡πÅ‡∏™‡∏î‡∏á log
                    log_text = ""
                    for log in log_messages:
                        icon = {
                            "info": "‚ÑπÔ∏è",
                            "success": "‚úÖ",
                            "warning": "‚ö†Ô∏è",
                            "error": "‚ùå"
                        }.get(log["status"], "üìù")
                        log_text += f"[{log['time']}] {icon} {log['message']}\n"
                    
                    log_expander.code(log_text, language=None)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á bot instance
                try:
                    if use_browser_mode:
                        st.info("üöÄ **‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î Chromium Browser...**")
                        st.info("üëÄ **Browser ‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÉ‡∏ô‡∏≠‡∏µ‡∏Å‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà - ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π Browser window!**")
                    
                    bot = DBDDataWarehouseBot(use_browser=use_browser_mode, headless=headless_mode)
                    
                    if use_browser_mode and bot.browser:
                        st.success("‚úÖ **Browser ‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!**")
                        st.info("üëÄ **‡∏î‡∏π Browser window ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà - ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå!**")
                        st.markdown("---")
                except Exception as e:
                    st.error(f"‚ùå **‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î Browser ‡πÑ‡∏î‡πâ:** {str(e)}")
                    st.warning("‚ö†Ô∏è **‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ Requests Mode ‡πÅ‡∏ó‡∏ô** (‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞ JavaScript protection)")
                    st.info("üí° **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**")
                    st.code("pip install playwright\nplaywright install chromium", language="bash")
                    # ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ requests mode
                    bot = DBDDataWarehouseBot(use_browser=False, headless=False)
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏° log callback)
                company_info = bot.search_company_info(company_name, log_callback=log_callback)
                
                if "error" in company_info:
                    st.error(f"‚ùå {company_info['error']}")
                else:
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 1148-1418)
                    st.success("‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó!")
                    st.markdown("---")
                    
                    # === ‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏ô: ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ===
                    header_col1, header_col2, header_col3 = st.columns([2, 2, 1])
                    with header_col1:
                        if company_info.get("company_name"):
                            st.markdown(f"**‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:** {company_info.get('company_name')}")
                    with header_col2:
                        if company_info.get("registration_number"):
                            st.markdown(f"**‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:** {company_info.get('registration_number')}")
                    with header_col3:
                        st.markdown(f"**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ì ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** {datetime.now().strftime('%d %b %y')}")
                    
                    st.markdown("---")
                    
                    def parse_card_values(raw_text: str) -> Tuple[str, str]:
                        """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å card-infos ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå"""
                        if not raw_text:
                            return "", ""

                        lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
                        values = {"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": "", "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå": ""}
                        current_label: Optional[str] = None

                        for line in lines:
                            normalized = line.replace(':', '').strip()

                            if normalized in values:
                                current_label = normalized
                                value = ""
                                if ':' in line:
                                    value = line.split(':', 1)[1].strip()

                                if value:
                                    values[normalized] = value
                                    current_label = None
                                else:
                                    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                                    values.setdefault(normalized, "")
                                continue

                            if current_label:
                                if values[current_label]:
                                    values[current_label] += f" {line}"
                                else:
                                    values[current_label] = line

                        return values.get("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à", ""), values.get("‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå", "")

                    # === ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà 1: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó (‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•) ===
                    st.subheader("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó")
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å - ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
                    info_items = []
                    info_values = []
                    
                    # 1. ‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                    if company_info.get("company_name"):
                        info_items.append("‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                        info_values.append(str(company_info.get("company_name", "-")))
                    
                    # 2. ‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                    if company_info.get("registration_number"):
                        info_items.append("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                        info_values.append(str(company_info.get("registration_number", "-")))
                    
                    # 3. ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà
                    if company_info.get("address"):
                        info_items.append("‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà")
                        address = str(company_info.get("address", "-"))
                        info_values.append(address.replace('\n', ' '))
                    
                    # 4. ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£ (‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
                    if company_info.get("directors"):
                        directors_text = company_info.get("directors", "").strip()
                        if directors_text:
                            directors_list = [d.strip() for d in directors_text.split('\n') if d.strip()]
                            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                            filtered_directors = []
                            for director in directors_list:
                                if '‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£' not in director:
                                    filtered_directors.append(director)
                            
                            if filtered_directors:
                                directors_str = " ".join([f"{i+1}. {d}" for i, d in enumerate(filtered_directors)])
                                info_items.append("‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£")
                                info_values.append(directors_str)
                    
                    # 5. ‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡∏Å‡∏û‡∏±‡∏ô
                    if company_info.get("authorized_signatories"):
                        auth_text = company_info.get("authorized_signatories", "").strip()
                        if auth_text:
                            if '‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡∏Å‡∏û‡∏±‡∏ô' in auth_text:
                                auth_text = auth_text.replace('‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡∏Å‡∏û‡∏±‡∏ô', '').strip()
                            info_items.append("‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡∏Å‡∏û‡∏±‡∏ô")
                            info_values.append(auth_text)
                    
                    # 6. ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                    if company_info.get("business_type"):
                        info_items.append("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                        info_values.append(str(company_info.get("business_type", "-")))
                    
                    # 7. ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•
                    if company_info.get("status"):
                        info_items.append("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                        status = str(company_info.get("status", "-"))
                        info_values.append(status)
                    
                    # 8. ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏à‡∏±‡∏î‡∏ï‡∏±‡πâ‡∏á
                    if company_info.get("found_date"):
                        info_items.append("‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏à‡∏±‡∏î‡∏ï‡∏±‡πâ‡∏á")
                        info_values.append(str(company_info.get("found_date", "-")))
                    
                    # 9. ‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô
                    if company_info.get("registered_capital"):
                        info_items.append("‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
                        info_values.append(str(company_info.get("registered_capital", "-")))
                    
                    # 10. ‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÄ‡∏î‡∏¥‡∏°
                    if company_info.get("old_registration_number"):
                        info_items.append("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÄ‡∏î‡∏¥‡∏°")
                        old_reg = str(company_info.get("old_registration_number", "-"))
                        info_values.append(old_reg if old_reg != "-" else "-")
                    
                    # 11. ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
                    if company_info.get("business_group"):
                        info_items.append("‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à")
                        info_values.append(str(company_info.get("business_group", "-")))
                    
                    # 12. ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
                    if company_info.get("business_size"):
                        info_items.append("‡∏Ç‡∏ô‡∏≤‡∏î‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à")
                        info_values.append(str(company_info.get("business_size", "-")))
                    
                    # 13. Website
                    if company_info.get("website"):
                        info_items.append("Website")
                        website = str(company_info.get("website", "-"))
                        if website.startswith('-'):
                            info_values.append(website)
                        elif website.startswith('http'):
                            info_values.append(f"- [{website}]({website})")
                        else:
                            info_values.append(f"- {website}")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                    if info_items:
                        info_data = {
                            "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£": info_items,
                            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•": info_values
                        }
                        df_result = pd.DataFrame(info_data)
                        st.dataframe(df_result, use_container_width=True, hide_index=True)
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó")
                    
                    st.markdown("---")
                    
                    # === ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà 2: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ===
                    st.subheader("üè¢ ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
                    
                    biz_reg_type = (company_info.get("business_type_registration") or "").strip()
                    biz_reg_objective = (company_info.get("business_type_registration_objective") or "").strip()

                    if not (biz_reg_type or biz_reg_objective):
                        raw_text = (company_info.get("business_type_registration_raw") or "").strip()
                        if raw_text:
                            parsed_type, parsed_objective = parse_card_values(raw_text)
                            biz_reg_type = parsed_type.strip()
                            biz_reg_objective = parsed_objective.strip()

                    if biz_reg_type or biz_reg_objective:
                        reg_data = {
                            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": [biz_reg_type if biz_reg_type else "-"],
                            "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå": [biz_reg_objective if biz_reg_objective else "-"]
                        }
                        df_biz_reg = pd.DataFrame(reg_data)
                        st.dataframe(df_biz_reg, use_container_width=True, hide_index=True)
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ï‡∏≠‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
                    
                    st.markdown("---")
                    
                    # === ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà 3: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏õ‡∏µ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ===
                    st.subheader("üìä ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏õ‡∏µ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
                    
                    biz_latest_type = (company_info.get("business_type_latest") or "").strip()
                    biz_latest_objective = (company_info.get("business_type_latest_objective") or "").strip()

                    if not (biz_latest_type or biz_latest_objective):
                        raw_latest_text = (company_info.get("business_type_latest_raw") or "").strip()
                        if raw_latest_text:
                            parsed_type, parsed_objective = parse_card_values(raw_latest_text)
                            biz_latest_type = parsed_type.strip()
                            biz_latest_objective = parsed_objective.strip()

                    if biz_latest_type or biz_latest_objective:
                        latest_data = {
                            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à": [biz_latest_type if biz_latest_type else "-"],
                            "‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå": [biz_latest_objective if biz_latest_objective else "-"]
                        }
                        df_biz_latest = pd.DataFrame(latest_data)
                        st.dataframe(df_biz_latest, use_container_width=True, hide_index=True)
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏õ‡∏µ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
                    
                    # === ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Expander) ===
                    if company_info.get("company_details"):
                        st.markdown("---")
                        with st.expander("üìÑ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏¢‡∏≤‡∏¢)", expanded=False):
                            # ‡πÅ‡∏¢‡∏Å‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏´‡∏ç‡πà
                            details_text = company_info.get("company_details", "").strip()
                            if details_text:
                                lines = details_text.split('\n')
                                current_section = None
                                
                                for line in lines:
                                    line = line.strip()
                                    if not line:
                                        continue
                                    
                                    # ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å (‡πÑ‡∏°‡πà‡∏°‡∏µ ":")
                                    if '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•' in line and ':' not in line:
                                        current_section = "company_info"
                                        st.markdown(f"### {line}")
                                        continue
                                    elif '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à' in line and ':' not in line:
                                        if current_section:
                                            st.markdown("---")
                                        current_section = "business_group"
                                        st.markdown(f"### {line}")
                                        continue
                                    elif '‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô' in line and ':' not in line:
                                        if current_section:
                                            st.markdown("---")
                                        current_section = "financial_years"
                                        st.markdown(f"### {line}")
                                        continue
                                    elif '‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà' in line and ':' not in line:
                                        if current_section:
                                            st.markdown("---")
                                        current_section = "address"
                                        st.markdown(f"### {line}")
                                        continue
                                    elif 'Website' in line and ':' not in line:
                                        if current_section:
                                            st.markdown("---")
                                        current_section = "website"
                                        st.markdown(f"### {line}")
                                        continue
                                    
                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Key-Value
                                    if ':' in line:
                                        parts = line.split(':', 1)
                                        if len(parts) == 2:
                                            key = parts[0].strip()
                                            value = parts[1].strip()
                                            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô URL ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô link
                                            if value.startswith('http') or '://' in value:
                                                st.markdown(f"**{key}:** - [{value}]({value})")
                                            else:
                                                st.markdown(f"**{key}:** {value}")
                                        else:
                                            st.write(line)
                                    else:
                                        # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡πÄ‡∏ä‡πà‡∏ô note)
                                        st.write(line)
                            else:
                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
    
    elif mode == "üìä ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel":
        st.subheader("üìä ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel")
        
        uploaded_excel_bot = st.file_uploader(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel",
            type=['xlsx', 'xls'],
            help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
            key="excel_upload_bot"
        )
        
        if uploaded_excel_bot is not None:
            try:
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel
                df_excel_bot = pd.read_excel(uploaded_excel_bot)
                
                st.success("‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
                st.subheader("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
                st.write(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß:** {len(df_excel_bot)}")
                st.write(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:** {len(df_excel_bot.columns)}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
                st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà:**")
                st.write(", ".join(df_excel_bot.columns.tolist()))
                
                # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
                company_columns = [col for col in df_excel_bot.columns if any(keyword in col.lower() for keyword in ['‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó', '‡∏ä‡∏∑‡πà‡∏≠', 'company', 'name'])]
                
                if company_columns:
                    selected_column_bot = st.selectbox(
                        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•:",
                        company_columns,
                        help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
                        key="company_column_bot"
                    )
                    
                    if selected_column_bot:
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
                        st.subheader("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
                        st.dataframe(df_excel_bot.head(10), use_container_width=True)
                        
                        # ‡∏õ‡∏∏‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                        if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•", type="primary", use_container_width=True, key="process_excel_bot"):
                            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ browser mode
                            if use_browser_mode and not headless_mode:
                                st.info("üëÄ **‡∏î‡∏π Chromium Browser ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà** - ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå!")
                            
                            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD
                            df_excel_with_dbd = integrate_with_streamlit(
                                df_excel_bot.copy(), 
                                selected_column_bot,
                                use_browser=use_browser_mode,
                                headless=headless_mode
                            )
                            
                            # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD
                            dbd_summary = create_dbd_summary_table(df_excel_with_dbd)
                            
                            if not dbd_summary.empty:
                                st.subheader("üìã ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD")
                                st.dataframe(dbd_summary, use_container_width=True)
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD
                            output_dbd = io.BytesIO()
                            with pd.ExcelWriter(output_dbd, engine='openpyxl') as writer:
                                df_excel_with_dbd.to_excel(writer, sheet_name='‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD', index=False)
                                
                                if not dbd_summary.empty:
                                    dbd_summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD', index=False)
                            
                            output_dbd.seek(0)
                            
                            st.download_button(
                                label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD",
                                data=output_dbd.getvalue(),
                                file_name=f"excel_with_dbd_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                help="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Excel ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD DataWarehouse",
                                key="download_dbd_bot"
                            )
                            
                            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
                            st.subheader("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß")
                            st.dataframe(df_excel_with_dbd, use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                    st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà:**")
                    for col in df_excel_bot.columns:
                        st.write(f"‚Ä¢ {col}")
            
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel: {str(e)}")

def render_receipt_bot_page():
    """‡∏´‡∏ô‡πâ‡∏≤ Bot ‡∏£‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à - ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö ‡πÅ‡∏Ñ‡πà‡∏õ‡∏∏‡πà‡∏°‡πÑ‡∏ß‡πâ"""
    st.header("üßæ Bot ‡∏£‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à")
    st.markdown("---")
    st.write("**‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥**")
    st.info("üéØ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DBD ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö PEAKEngine")

    uploaded_peak_excel = st.file_uploader(
        "üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏µ‡∏ï '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD'",
        type=['xlsx', 'xls'],
        help="‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD' ‡πÅ‡∏•‡∏∞ '‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
    )

    def normalize_registration_number(reg_value):
        if pd.isna(reg_value):
            return ""
        reg_str = str(reg_value).strip()
        if not reg_str:
            return ""
        digits = "".join(ch for ch in reg_str if ch.isdigit())
        if not digits:
            return ""
        digits = digits[-13:]
        if len(digits) < 13:
            digits = digits.zfill(13)
        if digits[0] != "0":
            digits = "0" + digits[1:]
        return digits

    def parse_dbd_info(text: str) -> Dict[str, str]:
        results = {}
        if not text or pd.isna(text):
            return results
        parts = [part.strip() for part in str(text).split('|')]
        for part in parts:
            if ':' not in part:
                continue
            key, value = part.split(':', 1)
            results[key.strip()] = value.strip()
        return results

    if uploaded_peak_excel is not None:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå Excel..."):
            try:
                excel_file = pd.ExcelFile(uploaded_peak_excel)
                if "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD" not in excel_file.sheet_names:
                    available_sheets = ", ".join(excel_file.sheet_names)
                    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏µ‡∏ï '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
                    if available_sheets:
                        st.info(f"üìÑ ‡∏ä‡∏µ‡∏ï‡∏ó‡∏µ‡πà‡∏û‡∏ö: {available_sheets}")
                else:
                    df_peak = pd.read_excel(excel_file, sheet_name="‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD")
                    st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ä‡∏µ‡∏ï '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° DBD' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session state ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                    st.session_state["peakengine_source_df"] = df_peak
                    st.session_state["peakengine_source_filename"] = getattr(uploaded_peak_excel, "name", "uploaded.xlsx")

                    st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", len(df_peak))
                    with col2:
                        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå", len(df_peak.columns))
                    with col3:
                        available_company_cols = [col for col in df_peak.columns if "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó" in str(col)]
                        st.metric("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏û‡∏ö", len(available_company_cols))

                    st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ä‡∏µ‡∏ï:**")
                    st.write(", ".join(df_peak.columns.astype(str).tolist()) or "-")

                    st.subheader("üîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å)")
                    st.dataframe(df_peak.head(5), use_container_width=True)

                    if available_company_cols:
                        st.caption(f"üéØ ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {', '.join(available_company_cols)}")
                    else:
                        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó' ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå")

                    reg_info_map: Dict[str, Dict[str, Any]] = {}
                    for idx_row, row in df_peak.iterrows():
                        dbd_raw = row.get("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD", "")
                        dbd_parsed = parse_dbd_info(dbd_raw)
                        reg_candidate = (
                            row.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
                            or row.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏à‡∏≤‡∏Å DBD")
                            or row.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•")
                            or dbd_parsed.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô")
                        )
                        reg_normalized = normalize_registration_number(reg_candidate)
                        if not reg_normalized:
                            continue
                        row_dict = row.to_dict()
                        reg_info_map[reg_normalized] = {
                            "registration": reg_normalized,
                            "dbd_raw": dbd_raw,
                            "dbd_info": dbd_parsed,
                            "transfer_type": str(row.get("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô", "")).strip(),
                            "company_name": row.get("‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD", ""),
                            "row_index": int(idx_row),
                            "row": row_dict
                        }
                    st.session_state["peakengine_reg_info_map"] = reg_info_map

                    if "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD" in excel_file.sheet_names:
                        df_summary = pd.read_excel(excel_file, sheet_name="‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD")

                        if "‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô" in df_summary.columns:
                            df_summary["‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô_‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"] = df_summary["‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"].apply(normalize_registration_number)
                        else:
                            df_summary["‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô_‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"] = ""

                        st.session_state["peakengine_summary_df"] = df_summary
                        st.subheader("üìë ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD")

                        reg_series = df_summary.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô_‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", df_summary.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"))
                        valid_reg = []
                        if reg_series is not None:
                            reg_series = reg_series.astype(str).str.strip()
                            valid_reg = [reg for reg in reg_series if reg and reg.lower() != "nan"]

                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß (‡∏™‡∏£‡∏∏‡∏õ)", len(df_summary))
                        with col2:
                            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á", len(valid_reg))
                        with col3:
                            unique_regs = list(dict.fromkeys(valid_reg))
                            st.metric("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥", len(unique_regs))

                        st.write("**‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô '‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD':**")
                        st.write(", ".join(df_summary.columns.astype(str).tolist()) or "-")

                        st.subheader("üîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å '‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD' (5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å)")
                        st.dataframe(df_summary.head(5), use_container_width=True)
                    else:
                        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏µ‡∏ï '‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏Å‡∏ú‡∏π‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ")

            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel: {str(e)}")
    else:
        st.info("üì• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

    summary_df = st.session_state.get("peakengine_summary_df")
    if summary_df is not None and not summary_df.empty:
        st.markdown("---")
        st.subheader("üßæ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô PEAKEngine")

        reg_series = summary_df.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô_‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", summary_df.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"))
        if reg_series is None:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô' ‡πÉ‡∏ô‡∏ä‡∏µ‡∏ï '‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD'")
            return

        reg_series = reg_series.astype(str).str.strip()
        registration_numbers = [reg for reg in reg_series if reg and reg.lower() != "nan"]
        unique_registration_numbers = list(dict.fromkeys(registration_numbers))

        if not registration_numbers:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏Å")
            return

        processed_list = st.session_state.get("peakengine_processed_regs", [])
        processed_set = set(processed_list)
        pending_numbers = [reg for reg in registration_numbers for _ in [reg] if reg not in processed_set]
        pending_unique_numbers = [reg for reg in unique_registration_numbers if reg not in processed_set]

        st.write(f"üìå ‡∏û‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(registration_numbers)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ {len(unique_registration_numbers)})")

        col_stats1, col_stats2, col_stats3 = st.columns(3)
        with col_stats1:
            st.metric("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß", len(processed_set))
        with col_stats2:
            st.metric("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠", len(pending_numbers))
        with col_stats3:
            st.metric("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ (‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)", len(pending_unique_numbers))

        st.caption("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏£‡∏≠‡∏Å‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠")

        fill_mode = st.radio(
            "‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å:",
            ["‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏Å‡∏£‡∏≠‡∏Å‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠)"],
            key="peak_fill_mode",
            horizontal=True
        )

        selected_registration = None
        if fill_mode == "‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£":
            selected_registration = st.selectbox(
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Å‡∏£‡∏≠‡∏Å:",
                pending_numbers if pending_numbers else registration_numbers,
                index=0 if pending_numbers or registration_numbers else None,
                key="selected_registration_number"
            )

            if not selected_registration:
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏Å")
                return
        else:
            # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Ñ‡πà‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏´‡∏°‡∏î
            st.session_state["selected_registration_number"] = ""

        if st.button("‚ôªÔ∏è ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß", key="reset_peak_processed"):
            st.session_state["peakengine_processed_regs"] = []
            st.success("‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            st.experimental_rerun()

        log_expander = st.expander("üìã Log ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", expanded=False)
        log_placeholder = log_expander.empty()
        log_messages: List[Dict[str, str]] = []

        def peak_log(message: str, status: str = "info"):
            icon_map = {
                "info": "‚ÑπÔ∏è",
                "success": "‚úÖ",
                "warning": "‚ö†Ô∏è",
                "error": "‚ùå"
            }
            log_messages.append({
                "time": datetime.now().strftime("%H:%M:%S"),
                "status": status,
                "message": message
            })
            lines = []
            for entry in log_messages[-200:]:
                icon = icon_map.get(entry["status"], "üìù")
                lines.append(f"[{entry['time']}] {icon} {entry['message']}")
            log_placeholder.code("\n".join(lines), language=None)

        col_fill_peak, col_newpeak = st.columns(2)
        with col_fill_peak:
            if st.button("üìù ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏•‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PEAK", type="primary", key="fill_peak_contacts_btn"):
                if config is None:
                    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå config.py ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö PEAKEngine ‡πÑ‡∏î‡πâ")
                    return

                username = getattr(config, 'PEAKENGINE_USERNAME', '')
                password = getattr(config, 'PEAKENGINE_PASSWORD', '')
                link_company = getattr(config, 'Link_conpany', None)
                link_receipt = getattr(config, 'Link_receipt', None)
                headless = getattr(config, 'HEADLESS_MODE', False)

                if not username or not password:
                    st.error("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î PEAKENGINE_USERNAME ‡πÅ‡∏•‡∏∞ PEAKENGINE_PASSWORD ‡πÉ‡∏ô config.py ‡∏Å‡πà‡∏≠‡∏ô")
                    return

                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö..."):
                    try:
                        from peakengine_bot import PeakEngineBot
                        bot = PeakEngineBot(use_browser=True, headless=headless)
                        _peakengine_bots.append(bot)

                        peak_log("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö PEAKEngine...", "info")
                        login_success = bot.login(username, password, link_company=link_company, link_receipt=link_receipt, log_callback=peak_log)

                        if not login_success:
                            st.error("‚ùå ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö PEAKEngine ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô config.py")
                            return

                        peak_log("‚úÖ ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô", "success")

                        if fill_mode == "‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£":
                            fill_targets = [selected_registration]
                        else:
                            if not pending_unique_numbers:
                                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏Å")
                                return
                            fill_targets = pending_unique_numbers
                            st.info(f"üîÅ ‡∏à‡∏∞‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(fill_targets)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥")

                        reg_info_map = st.session_state.get("peakengine_reg_info_map", {})
                        fill_result = bot.fill_contact_fields(
                            fill_targets,
                            reg_info_map=reg_info_map,
                            log_callback=peak_log
                        )

                        if "error" in fill_result:
                            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {fill_result['error']}")
                        else:
                            success_count = fill_result.get("success", 0)
                            total_count = fill_result.get("total", len(fill_targets))
                            error_list = fill_result.get("errors", [])
                            processed_values = fill_result.get("processed", [])

                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å", total_count)
                            with col2:
                                st.metric("‡∏Å‡∏£‡∏≠‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", success_count)
                            with col3:
                                st.metric("‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", len(error_list))

                            if processed_values:
                                processed_set.update(processed_values)
                                st.session_state["peakengine_processed_regs"] = list(processed_set)

                            if error_list:
                                st.warning("‚ö†Ô∏è ‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
                                df_errors = pd.DataFrame(error_list)
                                st.dataframe(df_errors, use_container_width=True)
                            else:
                                if fill_mode == "‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£":
                                    st.success("üéâ ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
                                else:
                                    st.success("üéâ ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

                            dropdown_data = fill_result.get("dropdown_options", [])
                            if dropdown_data:
                                st.subheader("üìã ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Dropdown ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏Å")
                                for entry in dropdown_data:
                                    value = entry.get("value", "")
                                    items = entry.get("items", [])
                                    st.write(f"**‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô:** {value}")
                                    if items:
                                        st.write(f"‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ({len(items)}):")
                                        st.code("\n".join(items), language=None)
                                    else:
                                        st.write("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô dropdown")

                            plus_clicks = fill_result.get("plus_clicked", [])
                            if plus_clicks:
                                st.info(f"üîÑ ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏¥‡∏Å '+ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏π‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô: {', '.join(plus_clicks)}")
                            elif dropdown_data:
                                st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏¥‡∏Å '+ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏π‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠' ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏ô dropdown")

                            selected_existing = fill_result.get("selected_existing", [])
                            if selected_existing:
                                st.success(f"‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏π‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô: {', '.join(selected_existing)}")

                            validation_results = fill_result.get("validation", [])
                            if validation_results:
                                st.subheader("üîç ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏±‡∏ö Excel")
                                for validation in validation_results:
                                    reg = validation.get("registration", "")
                                    st.write(f"**‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô:** {reg}")
                                    overall = validation.get("overall_match", False)
                                    if overall:
                                        st.success("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Excel ‡∏ó‡∏∏‡∏Å‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö")
                                    else:
                                        st.warning("‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏≤‡∏á‡∏ä‡πà‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Excel ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")
                                    details = validation.get("details", [])
                                    mismatch_rows = []
                                    for detail in details:
                                        field = detail.get("field", "")
                                        expected = detail.get("expected", "")
                                        actual = detail.get("actual", "")
                                        match = detail.get("match", False)
                                        status_symbol = "‚úÖ" if match else "‚ö†Ô∏è"
                                        mismatch_rows.append(f"{status_symbol} {field}\n  - Excel: {expected}\n  - ‡∏£‡∏∞‡∏ö‡∏ö: {actual}")
                                    st.code("\n".join(mismatch_rows), language=None)

                    except Exception as e:
                        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
                        peak_log(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}", "error")

        with col_newpeak:
            if st.button("üÜï ‡πÄ‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö New Peak (‡∏ó‡∏î‡∏•‡∏≠‡∏á)", key="open_newpeak_from_excel"):
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå New Peak..."):
                    if open_newpeak_login():
                        st.success("‚úÖ ‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î Browser ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö New Peak ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                        st.info("üëÄ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó New Peak")
                        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot..."):
                            newpeak_bot_instance = wait_for_newpeak_instance(timeout=45, poll_interval=0.5)
                            if newpeak_bot_instance and isinstance(newpeak_bot_instance, NewPeakBot):
                                st.session_state["active_newpeak_bot"] = newpeak_bot_instance
                                peak_log("‚úÖ ‡∏û‡∏ö‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", "success")
                            else:
                                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö log")
                                peak_log("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î", "warning")
                                return
                        df_source = st.session_state.get("peakengine_source_df")
                        if df_source is None or df_source.empty:
                            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Excel ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
                        else:
                            amount_col = None
                            if "‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric" in df_source.columns:
                                amount_col = "‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric"
                            elif "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô" in df_source.columns:
                                amount_col = "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô"
                            type_col = "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô" if "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô" in df_source.columns else None
                            dbd_col = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD" if "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD" in df_source.columns else None
                            company_col = None
                            for candidate in ["‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD", "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏à‡∏≤‡∏Å DBD", "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"]:
                                if candidate in df_source.columns:
                                    company_col = candidate
                                    break

                            if not amount_col or not type_col or not dbd_col:
                                missing_cols = []
                                if not amount_col:
                                    missing_cols.append("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ ‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô_numeric")
                                if not type_col:
                                    missing_cols.append("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô")
                                if not dbd_col:
                                    missing_cols.append("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD")
                                st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {', '.join(missing_cols)}")
                            else:
                                try:
                                    newpeak_bot = st.session_state.get("active_newpeak_bot")
                                    if not isinstance(newpeak_bot, NewPeakBot):
                                        newpeak_bot = wait_for_newpeak_instance(timeout=30, poll_interval=0.5)
                                        if isinstance(newpeak_bot, NewPeakBot):
                                            st.session_state["active_newpeak_bot"] = newpeak_bot
                                            peak_log("‚ÑπÔ∏è ‡πÉ‡∏ä‡πâ NewPeakBot ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡∏¥‡∏ß", "info")
                                    if not isinstance(newpeak_bot, NewPeakBot):
                                        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
                                        peak_log("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå NewPeakBot ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", "warning")
                                    else:
                                        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏≠‡πÉ‡∏´‡πâ NewPeakBot ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö..."):
                                            if not wait_for_newpeak_login(newpeak_bot, timeout=90, poll_interval=0.5, log_callback=peak_log):
                                                st.warning("‚ö†Ô∏è ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö New Peak ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
                                                peak_log("‚ö†Ô∏è ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö New Peak ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î", "warning")
                                                return
                                        peak_log("‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ NewPeakBot", "success")
                                        tasks, skipped_records = newpeak_bot.prepare_transaction_tasks(
                                            df_source.copy(),
                                            amount_column=amount_col,
                                            type_column=type_col,
                                            dbd_column=dbd_col,
                                            company_column=company_col,
                                        )

                                        selected_registration = st.session_state.get("selected_registration_number", "")
                                        fill_mode_value = st.session_state.get("peak_fill_mode")

                                        def normalize_registration(value: Any) -> str:
                                            if value is None or (isinstance(value, float) and pd.isna(value)):
                                                return ""
                                            text = str(value).strip()
                                            digits = "".join(ch for ch in text if ch.isdigit())
                                            if len(digits) >= 13:
                                                return digits[-13:]
                                            if len(digits) == 0:
                                                return ""
                                            return digits.zfill(13)

                                        def normalize_company_name(value: Any) -> str:
                                            if value is None or (isinstance(value, float) and pd.isna(value)):
                                                return ""
                                            text = str(value).lower()
                                            replacements = [
                                                "‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó",
                                                "‡∏à‡∏≥‡∏Å‡∏±‡∏î",
                                                "‡∏°‡∏´‡∏≤‡∏ä‡∏ô",
                                                "(‡∏°‡∏´‡∏≤‡∏ä‡∏ô)",
                                                "‡∏´‡πâ‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô",
                                                "‡∏´‡∏à‡∏Å.",
                                                "‡∏ö‡∏à‡∏Å.",
                                                "‡∏Ñ‡∏≠‡∏£‡πå‡∏õ‡∏≠‡πÄ‡∏£‡∏ä‡∏±‡πà‡∏ô",
                                            ]
                                            for token in replacements:
                                                text = text.replace(token.lower(), " ")
                                            text = re.sub(r"[\"'.,()]", " ", text)
                                            text = re.sub(r"\s+", " ", text)
                                            return text.strip()

                                        registrations_in_tasks = [
                                            normalize_registration(task.get("registration"))
                                            for task in tasks
                                            if task.get("registration")
                                        ]
                                        if registrations_in_tasks:
                                            preview_sample = ", ".join(registrations_in_tasks[:10])
                                            if len(registrations_in_tasks) > 10:
                                                preview_sample += ", ..."
                                            peak_log(
                                                f"üóÇ ‡∏û‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: {preview_sample}",
                                                "info",
                                            )
                                        else:
                                            peak_log(
                                                "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô/‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô)",
                                                "warning",
                                            )

                                        if fill_mode_value == "‡∏Å‡∏£‡∏≠‡∏Å‡∏ó‡∏µ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£":
                                            normalized_selected = normalize_registration(selected_registration)
                                            if normalized_selected:
                                                filtered_tasks = [
                                                    task for task in tasks
                                                    if normalize_registration(task.get("registration")) == normalized_selected
                                                ]
                                                if not filtered_tasks:
                                                    # ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
                                                    df_matches = pd.DataFrame()
                                                    selected_rows = pd.DataFrame()
                                                    if dbd_col in df_source.columns:
                                                        selected_rows = df_source[
                                                            df_source[dbd_col]
                                                            .astype(str)
                                                            .str.replace(r"\D", "", regex=True)
                                                            .str[-13:]
                                                            .fillna("")
                                                            == normalized_selected
                                                        ]
                                                        df_matches = selected_rows.copy()
                                                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD
                                                    if df_matches.empty and company_col:
                                                        normalized_company_series = (
                                                            df_source[company_col]
                                                            .astype(str)
                                                            .apply(normalize_company_name)
                                                        )
                                                        target_names: List[str] = []
                                                        if not selected_rows.empty and company_col in selected_rows.columns:
                                                            target_names = (
                                                                selected_rows[company_col]
                                                                .astype(str)
                                                                .apply(normalize_company_name)
                                                                .unique()
                                                                .tolist()
                                                            )
                                                        if target_names:
                                                            df_matches = df_source[normalized_company_series.isin(target_names)]
                                                    if not df_matches.empty:
                                                        peak_log(
                                                            "‚ÑπÔ∏è ‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô Excel ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô "
                                                            "‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô)",
                                                            "info",
                                                        )
                                                        st.info(
                                                            "‚ÑπÔ∏è ‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô Excel ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô "
                                                            "‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô/‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á‡πÇ‡∏≠‡∏ô/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD)"
                                                        )
                                                        display_cols = [
                                                            col
                                                            for col in df_matches.columns
                                                            if col
                                                            in [
                                                                "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà",
                                                                amount_col,
                                                                type_col,
                                                                dbd_col,
                                                            ]
                                                        ]
                                                        if company_col and company_col in df_matches.columns:
                                                            display_cols.insert(0, company_col)
                                                        st.dataframe(
                                                            df_matches[display_cols],
                                                            use_container_width=True,
                                                        )
                                                    peak_log(
                                                        f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô Excel ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô {normalized_selected}",
                                                        "warning",
                                                    )
                                                    st.warning(
                                                        f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô Excel ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô {normalized_selected}"
                                                    )
                                                    return
                                                else:
                                                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏ö task ‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡∏ï‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô 13 ‡∏´‡∏•‡∏±‡∏Å
                                                    summary_df = st.session_state.get("peakengine_summary_df")
                                                    summary_registration = ""
                                                    matched_row_indices = [task.get("row_index") for task in filtered_tasks if task.get("row_index") is not None]
                                                    matched_rows = (
                                                        df_source.loc[matched_row_indices]
                                                        if matched_row_indices
                                                        else pd.DataFrame()
                                                    )
                                                    company_name_candidates = []
                                                    task_company_candidates = [
                                                        normalize_company_name(task.get("company_name"))
                                                        for task in filtered_tasks
                                                        if task.get("company_name")
                                                    ]
                                                    company_name_candidates.extend(
                                                        [name for name in task_company_candidates if name]
                                                    )
                                                    if not matched_rows.empty and company_col and company_col in matched_rows.columns:
                                                        company_name_candidates = (
                                                            matched_rows[company_col]
                                                            .astype(str)
                                                            .apply(normalize_company_name)
                                                            .tolist()
                                                        )
                                                    if isinstance(summary_df, pd.DataFrame) and not summary_df.empty:
                                                        name_column = None
                                                        for candidate_col in ["‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD", "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó", "‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"]:
                                                            if candidate_col in summary_df.columns:
                                                                name_column = candidate_col
                                                                break
                                                        normalized_names = (
                                                            summary_df[name_column].astype(str).apply(normalize_company_name)
                                                            if name_column
                                                            else pd.Series(dtype=str)
                                                        )
                                                        summary_df["_normalized_name"] = normalized_names
                                                        summary_df["_reg_digits"] = (
                                                            summary_df.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô_‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", summary_df.get("‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"))
                                                            .astype(str)
                                                            .str.replace(r"\D", "", regex=True)
                                                            .str[-13:]
                                                            .fillna("")
                                                        )
                                                        candidates = summary_df[
                                                            summary_df["_reg_digits"] == normalized_selected
                                                        ]
                                                        if candidates.empty and company_name_candidates:
                                                            candidates = summary_df[
                                                                summary_df["_normalized_name"].isin(company_name_candidates)
                                                            ]
                                                            if not candidates.empty:
                                                                summary_registration = candidates["_reg_digits"].iloc[0]
                                                                st.success(
                                                                    f"‚úÖ ‡∏û‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏ä‡∏µ‡∏ï '‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD': {summary_registration}"
                                                                )
                                                                st.dataframe(
                                                                    candidates[
                                                                        [
                                                                            col
                                                                            for col in candidates.columns
                                                                            if col
                                                                            in [
                                                                                "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏à‡∏≤‡∏Å DBD",
                                                                                "‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô",
                                                                                "‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô_‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô",
                                                                                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à",
                                                                                "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞",
                                                                                "‡∏ó‡∏∏‡∏ô‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô",
                                                                            ]
                                                                        ]
                                                                    ],
                                                                    use_container_width=True,
                                                                )
                                                    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD ‡∏ó‡∏µ‡πà parse ‡πÅ‡∏•‡πâ‡∏ß
                                                    details_list = [
                                                        task.get("dbd_details", {})
                                                        for task in filtered_tasks
                                                        if task.get("dbd_details")
                                                    ]
                                                    if details_list:
                                                        st.success(f"‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô {normalized_selected}")
                                                        details_df = pd.DataFrame(details_list)
                                                        st.dataframe(details_df, use_container_width=True)
                                                        peak_log(
                                                            f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DBD ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô {normalized_selected}",
                                                            "success",
                                                        )
                                                peak_log(
                                                    f"‚ÑπÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô {normalized_selected} ({len(filtered_tasks)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)",
                                                    "info",
                                                )
                                                tasks = filtered_tasks
                                            else:
                                                st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Å‡∏£‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
                                                peak_log("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Å‡∏£‡∏≠‡∏Å", "warning")
                                                return

                                        preview_df = pd.DataFrame(tasks)
                                        skipped_df = pd.DataFrame(skipped_records)

                                        with st.expander("üóÇ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡∏£‡∏≠‡∏Å (New Peak)", expanded=True):
                                            if preview_df.empty:
                                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö New Peak")
                                            else:
                                                preview_columns = [
                                                    "row_number",
                                                    "amount",
                                                    "transfer_type",
                                                    "dbd_has_data",
                                                    "registration",
                                                ]
                                                if "company_name" in preview_df.columns:
                                                    preview_columns.append("company_name")
                                                preview_columns.append("target_url")
                                                available_preview_columns = [
                                                    col for col in preview_columns if col in preview_df.columns
                                                ]
                                                st.dataframe(
                                                    preview_df[available_preview_columns],
                                                    use_container_width=True,
                                                )
                                        if not skipped_df.empty:
                                            with st.expander("‚ö†Ô∏è ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Ç‡πâ‡∏≤‡∏° (New Peak)", expanded=False):
                                                st.dataframe(skipped_df, use_container_width=True)

                                        peak_log("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Excel ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö New Peak...", "info")
                                        result = newpeak_bot.process_excel_transactions(
                                            df_source.copy(),
                                            amount_column=amount_col,
                                            type_column=type_col,
                                            dbd_column=dbd_col,
                                            company_column=company_col,
                                            log_callback=peak_log,
                                            prepared_tasks=tasks,
                                            skipped_info=skipped_records,
                                        )
                                        if "error" in result:
                                            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ: {result['error']}")
                                        else:
                                            st.success("‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö New Peak ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                                            col_np1, col_np2, col_np3 = st.columns(3)
                                            with col_np1:
                                                st.metric("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", result.get("processed", 0))
                                            with col_np2:
                                                st.metric("‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≤‡∏°", result.get("skipped", 0))
                                            with col_np3:
                                                st.metric("‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", len(result.get("errors", [])))

                                            skipped_details = result.get("skipped_details", [])
                                            if skipped_details:
                                                with st.expander("‚ÑπÔ∏è ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç", expanded=False):
                                                    st.dataframe(
                                                        pd.DataFrame(skipped_details),
                                                        use_container_width=True,
                                                    )
                                            if result.get("errors"):
                                                st.warning("‚ö†Ô∏è ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")
                                                st.dataframe(pd.DataFrame(result["errors"]), use_container_width=True)
                                except Exception as exc:
                                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• New Peak: {exc}")
                                    peak_log(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• New Peak: {exc}", "error")
                    else:
                        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á NewPeakBot ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö log ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå config.py")

def main():
    st.title("üè¶ ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô Excel")
    st.markdown("---")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå‡∏Ç‡∏≠‡∏á BankPDFReader
    reader = BankPDFReader()
    
    # Sidebar ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
    st.sidebar.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤
    st.sidebar.subheader("üìë ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤")
    page = st.sidebar.radio(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:",
        ["üìÑ Statement", "ü§ñ Bot ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏°‡∏û‡∏±‡∏í‡∏ô‡πå", "üßæ Bot ‡∏£‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à"],
        help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
    )
    
    st.sidebar.markdown("---")
    
    # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PeakEngine
    st.sidebar.subheader("üåê ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö")
    if st.sidebar.button("üîê ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤ PeakEngine Login", use_container_width=True, help="‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PeakEngine Login, ‡∏Å‡∏£‡∏≠‡∏Å username/password, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡πÅ‡∏•‡∏∞ navigate ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å config.py", key="open_peakengine_btn"):
        with st.sidebar:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö PeakEngine, ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡πÅ‡∏•‡∏∞ navigate ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏•‡∏¥‡∏á‡∏Ñ‡πå..."):
                if open_peakengine_login():
                    st.success("‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö, ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡πÅ‡∏•‡∏∞ navigate ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏•‡∏¥‡∏á‡∏Ñ‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                    st.info("üëÄ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á Browser ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ - ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞ login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡πÅ‡∏•‡∏∞ navigate ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥")
                    if config and hasattr(config, 'PEAKENGINE_USERNAME') and config.PEAKENGINE_USERNAME:
                        st.info(f"üìß Username: {config.PEAKENGINE_USERNAME}")
                    if config:
                        if hasattr(config, 'Link_conpany'):
                            st.info(f"üîó Link_conpany: {config.Link_conpany}")
                        if hasattr(config, 'Link_receipt'):
                            st.info(f"üîó Link_receipt: {config.Link_receipt}")
                else:
                    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö, login, ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° PEAK (Deprecated) ‡∏´‡∏£‡∏∑‡∏≠ navigate ‡πÑ‡∏î‡πâ")
    if st.sidebar.button("üÜï ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤ New Peak Login", use_container_width=True, help="‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö https://secure.peakaccount.com ‡∏î‡πâ‡∏ß‡∏¢ NewPeakBot ‡πÅ‡∏•‡∏∞ navigate ‡∏ï‡∏≤‡∏° config.py", key="open_newpeak_btn"):
        with st.sidebar:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö New Peak, ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå..."):
                if open_newpeak_login():
                    st.success("‚úÖ ‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î Browser ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö New Peak ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏î‡∏π‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ö‡∏≠‡∏ó")
                    if config:
                        username = getattr(config, "NEWPEAK_USERNAME", getattr(config, "PEAKENGINE_USERNAME", ""))
                        if username:
                            st.info(f"üìß Username: {username}")
                        if hasattr(config, "Link_compay_newpeak"):
                            st.info(f"üîó Link_compay_newpeak: {getattr(config, 'Link_compay_newpeak')}")
                        if hasattr(config, "Link_receipt_newpeak"):
                            st.info(f"üîó Link_receipt_newpeak: {getattr(config, 'Link_receipt_newpeak')}")
                else:
                    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á NewPeakBot ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö log ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå config.py")
    
    st.sidebar.markdown("---")
    
    # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ö‡∏≠‡∏ó DBD (‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏≠‡∏ó)
    use_browser_mode = False
    if "Bot" in page:
        st.sidebar.subheader("ü§ñ ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ö‡∏≠‡∏ó DBD")
        use_browser_mode = st.sidebar.checkbox(
            "üåê ‡πÉ‡∏ä‡πâ Playwright Browser (‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠)",
            value=True,  # ‡πÄ‡∏õ‡∏¥‡∏î browser ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
                help="‡πÄ‡∏õ‡∏¥‡∏î Playwright Chromium Browser ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå",
                key="use_browser_checkbox"
        )
    
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô session state
        st.session_state['use_browser_mode'] = use_browser_mode
        st.session_state['headless_mode'] = False  # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á browser ‡πÄ‡∏™‡∏°‡∏≠
    
    if use_browser_mode:
        st.sidebar.success("üëÄ **Browser ‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå!**")
        st.sidebar.info("üí° **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** ‡∏î‡∏π Browser window ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ - ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏ó‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
        st.sidebar.markdown("""
        **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô:**
        1. üåê ‡πÄ‡∏õ‡∏¥‡∏î Browser
        2. üìç ‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö DBD DataWarehouse
        3. üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ä‡πà‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        4. ‚å®Ô∏è ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
        5. üîò ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        6. üìä ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        """)

        if st.sidebar.button("üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î Playwright Browser", help="‡πÄ‡∏õ‡∏¥‡∏î Chromium ‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á playwright ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ", key="test_browser_btn"):
            with st.sidebar:
                with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î Playwright Chromium..."):
                    if test_playwright_browser():
                        st.success("‚úÖ ‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î Playwright ‡πÅ‡∏•‡πâ‡∏ß!")
                        st.info("üëÄ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á Chromium ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤")
                    else:
                        st.error("‚ùå ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Playwright ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                        st.sidebar.markdown("---")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£ (‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Statement)
    if page == "üìÑ Statement":
        st.sidebar.subheader("üè¶ ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ PDF")
        bank_names = list(reader.bank_configs.keys())
        selected_bank = st.sidebar.selectbox(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£:",
            bank_names,
                help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå PDF ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
                key="bank_select"
            )
    else:
        selected_bank = None
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
    if page == "üìÑ Statement":
        uploaded_file, selected_bank = render_statement_page(reader, selected_bank)
    elif page == "ü§ñ Bot ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏°‡∏û‡∏±‡∏í‡∏ô‡πå":
        render_dbd_bot_page(reader)
        uploaded_file = None
    elif page == "üßæ Bot ‡∏£‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à":
        render_receipt_bot_page()
        uploaded_file = None
    
    # Footer
    st.markdown("---")
    st.header("‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üè¶ ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö")
        bank_names = list(reader.bank_configs.keys())
        for bank in bank_names:
            st.write(f"‚Ä¢ {bank}")
    
    with col2:
        st.subheader("‚ú® ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå")
        features = [
            "‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥",
            "‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Excel",
            "‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡πà‡∏á",
            "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥",
            "‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
            "UI ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢"
        ]
        for feature in features:
            st.write(f"‚Ä¢ {feature}")
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            <p>üè¶ Bank PDF to Excel Converter | ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Streamlit</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
        
        
